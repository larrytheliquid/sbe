\documentclass{llncs}
\usepackage{etex} % trick to get xypic to load
\usepackage[authoryear,square]{natbib}
\usepackage{proof}

\usepackage{todonotes}
\usepackage{amsmath}
%% \usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{url}
\usepackage{bbm}
\usepackage[greek,english]{babel}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{autofe}
\usepackage{stmaryrd}
\usepackage{enumitem}
\usepackage[all]{xy}

\usepackage{tabularx}
\renewcommand{\arraystretch}{1.5} % more table padding

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}

\DeclareUnicodeCharacter{8988}{\ensuremath{\ulcorner}}
\DeclareUnicodeCharacter{8989}{\ensuremath{\urcorner}}
\DeclareUnicodeCharacter{8803}{\ensuremath{\overline{\equiv}}}
\DeclareUnicodeCharacter{8759}{\ensuremath{\colon\colon}}
\DeclareUnicodeCharacter{12314}{\ensuremath{\llbracket}}
\DeclareUnicodeCharacter{12315}{\ensuremath{\rrbracket}}
\DeclareUnicodeCharacter{10214}{\ensuremath{\llbracket}}
\DeclareUnicodeCharacter{10215}{\ensuremath{\rrbracket}}
\DeclareUnicodeCharacter{8614}{\ensuremath{\mapsto}}
\DeclareUnicodeCharacter{8799}{\ensuremath{\stackrel{?}{=}}}
\DeclareUnicodeCharacter{8669}{\ensuremath{\leadsto}}

\usepackage{fancyvrb}

\usepackage[labelfont=bf]{caption}

\newtheorem{defin}{Definition}

\spnewtheorem{mydefinition'}{Definition}{\bfseries}{\itshape}
\spnewtheorem{mytheorem'}{Theorem}{\bfseries}{\rmfamily}
\spnewtheorem*{mycase}{Case}{\bfseries}{\rmfamily}
\spnewtheorem*{myproof'}{Proof}{\itshape}{\rmfamily}

\newenvironment{mydefinition}[3]
{ \begin{mydefinition'}[#1] \label{def:#2}
  \hfill\break
  #3
}
{ \end{mydefinition'} }

\newenvironment{myproof}[1]
{ \begin{myproof'} \textit{#1} }
{ \myqed \end{myproof'} }

\newenvironment{mytheorem}[4]
{ \begin{mytheorem'}[#1] \label{thm:#2}
  $$#3$$

  \begingroup \small
  \begin{tabularx}{\textwidth}{ |c|c|c|X| }
    \hline #4 \hline
  \end{tabularx}
  \hfill \break  
  \endgroup
}
{ \end{mytheorem'} }

%% \newcommand{\thmdeps}[2]{
%% $$#1$$

%% \begin{tabularx}{\textwidth}{ |c|c|c|X| }
%%   \hline #2 \hline
%% \end{tabularx}
%% \hfill \break
%% }

\newtheorem{subdefin}{Case}
%% \numberwithin{subdefin}{defin}

%% \theoremstyle{definition}
%% \theoremstyle{plain}

%% \newtheorem{theorem}{Theorem}
\newtheorem{subtheorem}{Theorem}
%% \numberwithin{subtheorem}{theorem}
\newtheorem{sublemma}{Lemma}
%% \numberwithin{sublemma}{theorem}
%% \newtheorem{corollary}{Corollary}
%% \numberwithin{corollary}{theorem}

%% \newtheorem{case}{Case}
%% \numberwithin{case}{theorem}

\newtheorem{slcase}{Case}
%% \numberwithin{slcase}{sublemma}

\newtheorem{scase}{Case}
%% \numberwithin{scase}{subtheorem}

%% \newtheorem{lemma}{Lemma}

\newtheorem{lcase}{Case}
%% \numberwithin{lcase}{lemma}


\newcommand{\refdef}[1]{Definition \ref{def:#1}}
\newcommand{\refthm}[1]{Theorem \ref{thm:#1}}
\newcommand{\reflem}[1]{Lemma \ref{lem:#1}}

\newcommand{\reffig}[1]{Figure \ref{fig:#1}}
\newcommand{\refsec}[1]{Section \ref{sec:#1}}
\newcommand{\refparte}[1]{Part$_E$ \ref{parte:#1}}
\newcommand{\refparti}[1]{Part$_I$ \ref{parti:#1}}

\def\myqed{\nobreak\hfil
\penalty50\hskip1em\null\nobreak\hfil\squareforqed
\parfillskip=0pt\finalhyphendemerits=0\endgraf}

\def\cross{\times}
\def\dfn{\mapsto}
\def\bigstep{\Downarrow}
\def\arr{\supset}
\def\marr{\rightarrow}
\def\app{\cdot}
\def\lam{\lambda}
\def\nat{\mathbb{N}}
\def\emp{\epsilon}

\def\here{\con{here}}
\def\there{\con{there}}

\def\var{\con{var}}
\def\zero{\con{zero}}
\def\suc{\con{suc}}
\def\neut{\con{neut}}

\def\mrec{\el{\rec}}
\def\rec{\fun{rec}}
\def\rbs{\fun{rbs}}
\def\abs{\fun{abs}}

\def\reify{\fun{reify}}

\def\reflectn{\fun{reflect}}
\def\reflect{\reflectn}
\def\reflecte{\fun{reflects}}

\def\mono{\fun{mono}}
\def\monos{\fun{monos}}

\def\eval{\fun{eval}}
\def\cevalv{\fun{ceval}}
\def\cevaln{\fun{ceval}^\con{N}}

\def\lookup{\fun{lookup}}

\def\sbe{\fun{sbe}}
\def\nsbe{\fun{nsbe}}

\def\nbs{\fun{nbs}}

\def\idenv{\fun{idEnv}}
\def\midenv{\el{\fun{idEnv}}}

\def\bydef{(\textit{definition})}
\def\byass{(\textit{assumption})}
\def\bytri{(\textit{trivial})}
\newcommand{\ih}[1]{(\textit{i.h.}~ #1)}
\newcommand{\by}[1]{(#1)}

\newcommand{\turn}[1]{\vdash^\con{#1}}

\newcommand{\hsubn}[2]{[\sigma]#1=^\con{N}#2}
\newcommand{\hsub}[2]{[\sigma]#1=^\con{V}#2}
\newcommand{\hsubext}[3]{[\sigma, #1]#2=^\con{V}#3}

\newcommand{\ascribe}[2]{(#1 : #2)}
\newcommand{\all}[1]{\forall#1.~}
\newcommand{\ex}[1]{\exists#1.~}

\newcommand{\el}[1]{\llbracket ~ #1 ~ \rrbracket}

\newcommand{\wkne}[1]{\fun{wkn}^\con{E} ~ \Delta ~ #1}
\newcommand{\wknv}[1]{\fun{wkn}^\con{V} ~ \Delta ~ #1}
\newcommand{\wknn}[1]{\fun{wkn}^\con{N} ~ \Delta ~ #1}

\newcommand{\con}[1]{\textmd{#1}}
\newcommand{\fun}[1]{\textmd{#1}}

\newcommand{\typm}[1]{\el{\Gamma \vdash #1}}
\newcommand{\dtypm}[1]{\el{\Delta \vdash #1}}
\newcommand{\xtypm}[1]{\el{\Xi \vdash #1}}
\newcommand{\xdtypm}[1]{\el{\Xi, \Delta \vdash #1}}
\newcommand{\gdtypm}[1]{\el{\Gamma, \Delta \vdash #1}}
\newcommand{\gftypm}[1]{\el{\Gamma, \Phi \vdash #1}}
\newcommand{\gatypm}[1]{\el{\Gamma, A \vdash #1}}
\newcommand{\ctypm}[2]{\el{\Gamma , #1 \vdash #2}}

\newcommand{\type}[1]{\Gamma \turn{E} #1}
\newcommand{\dtype}[1]{\Delta \turn{E} #1}
\newcommand{\gdtype}[1]{\Gamma, \Delta \turn{E} #1}
\newcommand{\ctype}[2]{\Gamma , #1 \turn{E} #2}

\newcommand{\typv}[1]{\Gamma \turn{V} #1}
\newcommand{\dtypv}[1]{\Delta \turn{V} #1}
\newcommand{\gdtypv}[1]{\Gamma, \Delta \turn{V} #1}
\newcommand{\gatypv}[1]{\Gamma, A \turn{V} #1}
\newcommand{\ctypv}[2]{\Gamma , #1 \turn{V} #2}

\newcommand{\typn}[1]{\Gamma \turn{N} #1}
\newcommand{\dtypn}[1]{\Delta \turn{N} #1}
\newcommand{\gdtypn}[1]{\Gamma, \Delta \turn{N} #1}
\newcommand{\gatypn}[1]{\Gamma, A \turn{N} #1}
\newcommand{\ctypn}[2]{\Gamma , #1 \turn{N} #2}

\newcommand{\typr}[1]{\Gamma \turn{R} #1}
\newcommand{\dtypr}[1]{\Delta \turn{R} #1}
\newcommand{\ctypr}[2]{\Gamma , #1 \turn{R} #2}

\def\menv{\el{\fun{Env}}~\Gamma~\Delta}
\def\env{\fun{Env}~\Gamma~\Delta}
\def\enve{\fun{Env}^\con{E}~\Gamma~\Delta}
\newcommand{\dmenv}[1]{\el{\fun{Env}}~#1~\Delta}
\newcommand{\denv}[1]{\fun{Env}~#1~\Delta}
\newcommand{\gmenv}[1]{\el{\fun{Env}}~\Gamma~#1}
\newcommand{\genv}[1]{\fun{Env}~\Gamma~#1}
\newcommand{\cmenv}[2]{\el{\fun{Env}}~#1~#2}
\newcommand{\cenv}[2]{\fun{Env}~#1~#2}


%% \newcommand{\ren}[1]{\Gamma \le #1}
%% \def\dren{\ren{\Delta}}
%% \newcommand{\env}[1]{\Gamma \sqsubseteq #1}
%% \def\denv{\env{\Delta}}

\begin{document}

\frontmatter
\pagestyle{headings}

\title{Hereditary Substitution \\by Canonical Evaluation (SbE)}

\author{Larry Diehl \and Tim Sheard}

\institute{Portland State University\\
\email{\{ldiehl,sheard\}@cs.pdx.edu}}

\maketitle

\begin{abstract}

This paper is about termination proofs for the semantics of total lambda calculi.
We introduce a change in perspective about how one might
think about such proofs. The standard perspective is to prove that a relationally
specified semantics terminates, e.g. by using realizability predicates. Instead,
we promote the perspective that the termination proof implicitly defines
an \textit{intrinsic semantics}, e.g. Normalization by Evaluation (NbE) into a Kripke model.
Thus we think of the termination proof as an intrinsic functional semantics, as compared
to the (no longer necessary) extrinsic relational semantics.

Just as intrinsic typing of terms results in simpler metatheoretical definitions and provides
free theorems, intrinsic semantics does the same. Adopting this perspective
led us to an elegant proof
that hereditary substitution for G{\"o}del's System T terminates. This proof
reuses the Kripke model (of NbE) and introduces a new technique that we call
Hereditary Substitution by Canonical Evaluation (SbE). Furthermore,
our entire development is simple to formalize in a proof assistant, such as Agda.
\end{abstract}

%% \category{D.3}{Software}{Programming Languages}.

\keywords
Type theory; hereditary substitution; termination; formalization.

\section{Introduction}
\label{sec:intro}

Normalization by Evaluation (NbE)~\cite{TODO} is a model-theoretic
technique for defining the semantics of a $\lambda$-calculus. For
example, normalization for a total $\lambda$-calculus with inductive
types (such as G{\"o}del's System T) can be defined by first
evaluating a syntactic expression (possibly containing $\beta$-redexes) to a
Kripke model value, and then reifying the result to a syntactic value
(not containing any $\beta$-redexes).

\begin{displaymath}
    \xymatrix{
          {\forall (e : A)} 
          \ar[dr]_{\fun{norm}}
          \ar[r]^{\fun{eval}}
        & {\el{A}}
          \ar[d]^{\large{\fun{reify}}}
\\      & \exists (v : A) }
\end{displaymath}

NbE is especially convenient for formalizing the semantics of total
$\lambda$-calculi in dependently typed languages (such as
Coq~\cite{TODO}, Agda~\cite{TODO}, or Idris~\cite{TODO}), because the
proof of termination of the semantics is \textit{implicit} in its
definition. In other words, normalization can be defined as a total
function within the language.
In contrast, formalizing the semantics of expressions as a
relation (e.g. a small or big-step relation), or as a
coinductive function~\cite{TODO}, requires the additional overhead
of supplying an \textit{explicit}
termination proof \textit{a posteriori} using techniques such as
logical relations~\cite{TODO}.

In a standard type theory \textit{expressions} are emphasized and
their semantics is defined directly. Alternatively, a
\textit{canonical type theory} emphasizes \textit{values} and defines
the semantics of expressions in terms of hereditary substitution of
values. Values are not closed under ordinary substitution, because a
substitution can introduce a $\beta$-redex. Hereditary substitution
fixes this problem by reducing whenever a $\beta$-redex is created as
the result of substitution. But, it is not easy to show that
traditional proof-theoretic definitions (discussed below in
\refsec{proof-theoretic}) of hereditary substitution terminate in
dependently typed languages.

\textbf{Our contribution} is adapting NbE to canonical terms, giving us a model-theoretic
definition of hereditary substitution. We call this technique
``Hereditary Substitution by Canonical Evaluation (SbE)''. Defining
SbE requires us to introduce novel definitions, but we also get to
reuse the model from NbE, as well as some of its definitions. SbE is
defined by \textit{canonically evaluating} a syntactic value to a
Kripke model value, and then reifying back to a syntactic value.

\begin{displaymath}
    \xymatrix{
          \forall{\ascribe{v}{A}, \sigma}
          \ar[dr]_{\fun{hsub}}
          \ar[r]^{\fun{ceval}}
        & {\el{A}}
          \ar[d]^{\large{\fun{reify}}}
\\      & \exists{\ascribe{v'}{A}} }
\end{displaymath}

SbE is a functional definition of hereditary substitution that
contains an intrinsic termination proof, just like the functional
definition of normalization that you get from NbE. Thus, SbE is
amenable to formalization, allowing canonical type theory for
$\lambda$-calculi with inductive types to be defined in dependent type
theory. For simplicity, we use G{\"o}del's System T for our examples
in this paper, but SbE scales to systems with paramterized inductive
types (such as lists or trees) for the same reasons that NbE does.

\subsection{Proof Theoretic Semantics}
\label{sec:proof-theoretic}

Hereditary substitution has historically been studied in the context
of proof-theoretic semantics. A proof-theoretic semantics takes
syntactic inputs directly to syntactic outputs, without going through
an intermediate semantic model. Formalizing this approach in
dependently typed languages has been limited to simple calculi.
For example, \cite{TODO} show how to formalize the
semantics of the STLC in Agda using syntactic hereditary substitution.
The termination of the hereditary substitution function is witnessed
by lexicographic induction on terms and types, but this approach does
not scale to $\lambda$-calculi with inductive types.

The syntactic approach to hereditary substitution
demands less from the metalanguage than from a model-theoretic
approach (i.e. the metalanguage
function space is not needed to construct a model). A disadvantage is
that exposing the lexicographic termination argument requires changing
the structure of values, e.g. requiring values to be in spine
form.

\subsection{Outline}

After a brief discussion about our notation, the rest of the paper is
structured as follows:

\begin{itemize}
\item{\bf{\refsec{epred}}}
We review the definitions and state the theorems needed to prove termination of
an extrinsic big-step semantics for G{\"o}del's System T using a
realizability predicate.

\item{\bf{\refsec{emodel}}}
We review the definitions and prove the theorems needed to define an
intrinsic semantics for G{\"o}del's System T via NbE and a Kripke
model. We point out which theorems from \refsec{epred} that we get for
free.

\item{\bf{\refsec{vmodel}}}
We review why the extrinsic relational semantics for hereditary
substitution does not obviously terminate, and show what choices you
need to make when defining its realizability predicate. Instead of
proving termination in the more complex setting of extrinsic
semantics, we define hereditary substitution as an intrinsic
semantics.

\item{\bf{\refsec{list}}}
We show how to extend the intrinsic semantics to a language including
parametric inductive types (e.g. lists).

\item{\bf{\refsec{correctness}}}
We prove that normalization of expressions, defined in terms of
hereditary substitution, is sound and complete with respect to a
contextual equivalence relation for expressions.

\item{\bf{\refsec{related}}}
We discuss related work.
\end{itemize}

\subsection{Notation}

We define types and contexts for G{\"o}del's System T using a standard
BNF grammar in \reffig{gram}. However, we use intrinsically typed
terms instead of defining a grammar for expressions and an extrinsic
typing relation. Below is an example of the standard extrinsic typing
of expressions.

$$
e ::= ... ~ | ~ \con{zero} ~ | ~ \con{suc} ~ n ~ | ~ ...
$$

$$
\infer
  [\nat\con{-I}_2]
  {\Gamma \turn{E} \con{suc} ~ n : \nat}
{
  \Gamma \turn{E} n : \nat
}
$$

Instead, we use the proof terms of our typing relation as
intrinsically typed terms (combining both definitions above into the
single definition below).

$$
\infer
  [\con{suc} ~ n]
  {\type{\nat}}
{
  (n : \type{\nat})
}
$$

We label each premise with a variable to
the left of a colon, and the name of the typing rule shows how to use
it as a proof term by applying it to the premise labels. In other
words, the labels represent the derivations of the premises.

The letter appearing as the superscript to the turnstyle is part of
the name of each intrinsic typing judgment. For example, $\turn{E}$
types expressions in \reffig{type}, $\turn{V}$ types values in
\reffig{typv}, and $\turn{N}$ types neutrals in \reffig{typn}.

Finally, we have taken care to ensure that all of our constructions
are easily formalizable. For this reason, we
use use De Bruijn~\cite{TODO} variables. For example, our typing rule
for functions does not explicitly bind its variable.

$$
\infer
  [\lam b]
  {\type{A \arr B}}
{
  (b : \ctype{A}{B})
}
$$

Additionally, proof that a De Bruijn variable of a particular type
exists in the context is given by the $\turn{R}$ judgment in
\reffig{typr}. Mentioning a variable in a term thus requires evidence
that the variable judgment is satisfied.

$$
\infer
  [\fun{var} ~ i]
  {\type{A}}
{
  (i : \typr{A})
}
$$

\section{Overview of NbE and SbE}
\label{sec:overview}

First we review why proving termination of naive definitions of
normalization and hereditary substitution fails, and then we provide a
high-level overview of theorems and definitions necessary to define NbE
and SbE (which provably terminate, unlike the naive definitions).
Finally, we discuss the similarities and differences between NbE and
SbE.
Henceforth, the development will proceed in a top-down manner.
Each proof of a theorem first lists the lemmas it depends on, and
the section where the proof of the lemma can be found. Pre-existing
proofs that we reuse from the NbE literature can be found in the
appendices, while novel proofs are in the body of the paper.

\subsection{Termination Issues with Naive Definitions}

When defining normalization and hereditary substitution, the
main problem preventing an obvious termination
argument by structural induction is the lack of
an inductive hypothesis in the function application case.

\paragraph{Naive Normalization}
Consider the application case in the definition of strong normalization
below, given as a big-step binary relation between expressions.

$$
\infer
  []{f \app a \bigstep {b'}}
{
  f \bigstep \lam b
  &
  a \bigstep a'
  &
  [a'/\con{here}]b \bigstep b'
}
$$

After evaluating the function to a lambda, we need to
substitute the argument into the lambda body. This may introduce
new $\beta$-redexes, so we must evaluate again but
there is no obvious termination measure to justify this (we have
already appealed to two inductive hypotheses, and there are no others
available).

\paragraph{Naive Hereditary Substitution}
Consider the application case in the definition of hereditary substitution
below, given as a ternary relation between an input value, a mapping from
variables to values ($\sigma$), and a resulting value. Note that we
actually have two mutually defined relations, one for substituting
into a value and producing a new value ($\hsub{v}{v'}$), and another
for substituting into neutral but also producing a value
($\hsubn{n}{v}$).

$$
\infer
   []{\hsubn{(f \app a)}{b'}}
{
  \hsubn{f}{\lam b}
  &
  \hsub{a}{a'}
  &
  \hsubext{a'}{b}{b'}
}
$$

This relation is not obviously terminating for the same reason as
normalization. We have inductive hypotheses for substituting into the
function and substituting into the argument, but there is no inductive hypothesis for
substituting into the $\lambda$-body.

\subsection{The Model}

Recall that the problematic case for normalization and hereditary
substitution is function application. In NbE, normalization is no
longer the ``meaty'' definition given by case analyzes over all
possible expressions. Instead, evaluation is the ``meaty'' definition
that case analyzes all expressions. Evaluation takes an expression
to a \textit{model} value instead of a \textit{syntactic} value.
Thus, normalization can defined more simply as the composition of
evaluation to a model value, and reification back to a syntactic value.

So how can we define the model in a way that makes termination of the
application case of evaluation no longer problematic? How about the
Kripke model below?

\begin{mydefinition}{Model of Values}{mval}
{
The model of values $\typm{A}$ denotes a set (a type in the
metalanguage), and it is defined inductively on the structure
of (object language) types ($A$).
}

\begin{mycase}[Natural numbers]
$$
\typm{\nat} \dfn \typv{\nat}
$$
Syntactic natural number values are also natural numbers values in the
model.
\end{mycase}

\begin{mycase}[Functions]
$$
\typm{A \arr B} \dfn \all{\Delta} \gdtypm{A} \marr \gdtypm{B}
$$

The model of functions is a function in the metalanguage.
The model function takes a weakened model value (whose type is
the domain of the function) as an argument, and produces a
weakened element of the model (whose type is the codomain of the
function). Both the input and output values of the model function are
weakened by some arbitrary context $\Delta$, which can be empty.
\end{mycase}

\end{mydefinition}

So how does this model help us to define the application case of
evaluation? Well, the result of evaluation (rather than
normalization) is a model value (rather than a syntactic value).
Thus, evaluating the function produces a model
function (a function in the metalanguage), which we can apply to the model value produced by evaluating
the argument (in this case the weakening $\Delta$ is merely the empty
context). Hence, we can define the application case of evaluation in
an structurally terminating way since it only needs to appeal to the
two available inductive hypotheses.

Given that evaluation must map syntactic expressions to model values,
what should it do when it encounters a variable? We can make
evaluation take an additional argument, called the
``model environment'', mapping variables to model values. More
specifically, the model environment maps all variables in
some initial context $\Gamma$ to model values in some terminal context
$\Delta$.

\todo[inline]{Should we explain extending the env when evaluating the
  lambda case?}

\begin{mydefinition}{Model of Environments}{menv}
{
The model of environments $\menv$ is defined inductively on the structure
of the first context argument ($\Gamma$).
}

\begin{mycase}[Empty context]
$$
\dmenv{\emp} \dfn \top
$$
The empty context is trivially inhabited in the environment model.
\end{mycase}

\begin{mycase}[Context extension]
$$
\dmenv{(\Gamma, A)} \dfn \dmenv{\Gamma} \cross \dtypm{A}
$$

The environment model of a context extension consists of two parts,
given as a pair type. The first part
is the environment model of the context being extended ($\Gamma$). The second part
is a model value in the terminal context ($\Delta$),
whose type is the type of the context extension ($A$).

\end{mycase}

\end{mydefinition}

\subsection{Normalization by Evaluation}

So far we have seen the model of values and environments, and the
intuition behind the model enabling a terminating definition of evaluation.
Now let's take a closer look at how exactly to define normalization in
terms of evaluation. What theorems 
\footnote{Because the ``definition'' of normalization contains an
intrinsic termination proof, we refer to normalization, evaluation, and
related ``definitions'' as \textit{theorems} and \textit{lemmas}.}
do we need, and how do we instantiate these theorems in the proof of
normalization?

\begin{mytheorem}{Normalization by Evaluation}{nbe}
{
\fun{nbe} : \type{A} \marr \typv{A}
}
{
\refsec{TODO} & \refthm{TODO} & $\eval$ & $\type{A} \marr \menv \marr \dtypm{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\reify$ & $\typm{A} \marr \typv{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\midenv$ & $\all{\Gamma} \gmenv{\Gamma}$ \\
}

The high-level plan of NbE is to define
normalization as the composition of evaluation ($\eval$) of an expression to a
model value, and reification ($\reify$) to a syntactic value.
Normalization takes a syntactic expression to a model value,
while evaluation takes a syntactic expression \textit{and} a model
environment to a model value. So what should we use for the model
environment argument when defining normalization in terms of
evaluation? We can create an identity model environment ($\midenv$)
for any context ($\Gamma$). The identity model environment maps
syntactic variables in $\Gamma$ to model values of the same variables in $\Gamma$.

\begin{myproof}{}
\begin{align*}
x    &: \type{A} && \byass\\
\sigma &: \cmenv{\Gamma}{\Gamma} && \by{\midenv~\Gamma}\\
x'  &: \typm{A} && \by{\eval~x~\sigma}\\
x'' &: \typv{A} && \by{\reify~x'}
\end{align*}
\end{myproof}

\end{mytheorem}

%% \begin{displaymath}
%%     \xymatrix{
%%           {\typv{A} \cross \env} 
%%           \ar[dr]_{\fun{sbe}}
%%           \ar[r]^{\fun{ceval}}
%%         & {\dtypm{A}}
%%           \ar[d]^{\large{\fun{reify}}}
%% \\      & \dtypv{A} }
%% \end{displaymath}

\subsection{Hereditary Substitution by Canonical Evaluation}

How is the type of hereditary substitution different from that of
normalization? First, we are substituting into a \textit{value} rather
than normalizing an \textit{expression}. Second, hereditary
substitution also takes a \textit{syntactic} environment, a mapping of
variables to syntactic values, as an additional argument.

\begin{mydefinition}{Syntax of Environments}{senv}
{
The syntax of environments $\env$ is defined exactly like the model of
environments (\refdef{menv}, $\menv$), except it contains syntactic values
instead of model values.
}
\end{mydefinition}

\begin{mytheorem}{Hereditary Substitution by Canonical Evaluation}{sbe}
{
\sbe : \typv{A} \marr \env \marr \dtypv{A}
}
{
\refsec{TODO} & \refthm{TODO} & $\cevalv$ & $\typv{A} \marr \menv \marr \dtypm{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\reify$ & $\typm{A} \marr \typv{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\reflecte$ & $\env \marr \menv$ \\
}

Above are the theorems we need for SbE. In particular, notice that we
get to reuse $\reify$ from NbE.
The high-level plan of SbE is to define
hereditary substitution as the composition of
canonical evaluation ($\cevalv$) of a syntactic value to a
model value, and reification ($\reify$) back to a syntactic value.
What exactly is canonical evaluation? Recall that evaluation of
expressions turned syntactic expressions into model values, reducing
$\beta$-redexes and replacing variables with their definition in the
model environment ($\sigma$) along the way. On the other hand,
canonical evaluation takes a syntactic value and a model environment
to a model value. It will not come across $\beta$-redexes in the input
syntactic value, but replacing variables with model values (from
$\sigma$) may \textit{introduce} $\beta$-redexes that need to be
immediately reduced. Finally, the syntactic environment argument of
SbE is reflected ($\reflecte$) as a model environment, and is used as the model
environment argument of canonical evaluation.

\begin{myproof}{}
\begin{align*}
a    &: \typv{A} && \byass\\
\sigma   &: \env && \byass\\
\sigma'  &: \menv && \by{\reflecte~\sigma}\\
a'   &: \dtypm{A} && \by{\cevalv~a~\sigma'}\\
a''  &: \dtypv{A} && \by{\reify~A~a'}
\end{align*}
\end{myproof}

\end{mytheorem}

\subsection{NbE versus SbE}

In the world of expressions,
evaluation takes an additional argument (the model environment) compared
to normalization, which only takes the expression to reduce. But, in
the world of values hereditary substitution and canonical evaluation
both take a value, an environment, and produce a value. The only
difference is that canonical evaluation takes a model environment and
produces a model value. 
In other words, canonical evaluation \textit{is}
a model-theoretic hereditary substitution, compared to the typical
proof-theoretic hereditary substitution.
What a beautiful coincidence!

A consequence of this is that normalization (which does not already
have a syntactic environment argument) must invent a model
environment to pass to evaluation. Because normalization does not
change the value of free variables, the identity model environment
($\midenv$) is used. In contrast, hereditary substitution already has
a syntactic environment (that is used to look up the values of any free
variables), so canonical evaluation takes the 
reflection ($\reflecte$) of the syntactic environment as its model
environment argument.

Although there is a more direct correspondence between SbE and canonical
evaluation (than there is between NbE and evaluation), there is
nothing preventing us from defining a function on expressions that
normalizes $\beta$-redexes, and simultaneously performs hereditary
substitutions from an environment mapping variables to expressions.
This normalization plus hereditary substitution function ($\nsbe$) would take an
extra syntactic expression environment argument, creating a
corresponcence with evaluation that is just as direct as the one that
SbE enjoys.

$$
\nsbe : \type{A} \marr \enve \marr \dtype{A}
$$


\section{Canonical Evaluation}
\label{sec:vmod}

$$
\cevalv : \typv{A} \marr \menv \marr \dtypm{A}
$$

\hfill \break
\begin{tabularx}{\textwidth}{ |c|c|c|X| }
  \hline
  \refsec{TODO} & \refthm{TODO} & $\cevaln$ & $\typn{A} \marr \menv \marr \dtypm{A}$ \\
  \hline
  \refsec{TODO} & \refthm{TODO} & $\monos$ & $\all{\Delta} \gmenv{\Xi} \marr \gmenv{(\Xi, \Delta)}$ \\
  \hline
\end{tabularx}
\hfill \break

Evaluation (\refthm{mod:eval}) is a type-preserving translation from
an expression of the theory in some initial context, to a model value
in some terminal context. In addition to the expression parameter,
evaluation also requires an environment of model values
(\refdef{menv}). Each model value must be in the terminal context, and
a model value is required for each type in the initial context.
The interesting cases include the evaluation of the following terms:

\paragraph{Application} The whole point of the value model
(\refdef{mval}) is to make this case easy to define. Evaluating the
applied function results in a metalanguage function, which we can
apply to an empty context extension ($\emp$) and the result of
evaluating the argument of the function application.

\paragraph{Function} When evaluating a function (a $\lam$ term),
return type of evaluation is a model-level function. This means that
we get a model value from the domain of the model function, which we
can subsequently extend the model environment with. Lucky for us, as
the recursive evaluation of the $\lam$ body requires a context extended
with just the type we need! Of course this is no coincidence, as it is
the reason why evaluation requires an environment model parameter in
the first place. The more interesting part of evaluating the function
is that the value we get (to extend the environment with) has been
weakened by an arbitrary $\Delta$! Therefore, we must also weaken the
model environment, by appealing to the monotonicity lemma for
environments (\reflem{monos}).

\paragraph{Primitive recursion} When an expression for primitive
recursion ($\rec$), we can get inductive hypotheses for all the
arguments to the primitive recursion, but we must perform a version of
primitive recursion in the model using \reflem{mod:rec}.

\begin{mytheorem}{Canonical Evaluation of Values}{cevalv}
{
\cevalv : \typv{A} \marr \menv \marr \dtypm{A}
}
{
\refsec{TODO} & \refthm{TODO} & $\cevaln$ & $\typn{A} \marr \menv \marr \dtypm{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\monos$ & $\all{\Delta} \gmenv{\Xi} \marr \gmenv{(\Xi, \Delta)}$ \\
}

\begin{myproof}
{
By induction on the value $\typv{A}$.
}

\begin{mycase}[Zero]
\begin{align*}
n  &: \dtypv{\nat} && \by{\zero}\\
n  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Successor]
\begin{align*}
n   &: \typv{\nat} && \byass\\
\sigma  &: \menv && \byass\\
n'  &: \dtypm{\nat} && \ih{\cevalv~n~\sigma}\\
n'  &: \dtypv{\nat} && \bydef\\
m   &: \dtypv{\nat} && \by{\suc~n'}\\
m'  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Function]
\begin{align*}
b   &: \gatypv{B} && \byass\\
\sigma  &: \menv && \byass\\
\Xi& && \byass\\
a   &: \el{\Delta, \Xi \vdash A} && \byass\\
\sigma'  &: \gmenv{(\Delta, \Xi)} && \by{\monos~\Xi~\sigma}\\
b'  &: \dtypm{B} && \ih{\cevalv~b~(\sigma', a)}\\
\end{align*}
\end{mycase}

\begin{mycase}[Neutral]
\begin{align*}
a   &: \typn{A} && \byass\\
\sigma  &: \menv && \byass\\
a'  &: \dtypm{A} && \ih{\cevaln~a~\sigma}
\end{align*}
\end{mycase}


\end{myproof}

\end{mytheorem}

\subsection{Canonical Evaluation of Neutrals}

\begin{mytheorem}{Canonical Evaluation of Neutrals}{cevaln}
{
\cevaln : \typn{A} \marr \menv \marr \dtypm{A}
}
{
\refsec{TODO} & \refthm{TODO} & $\cevalv$ & $\typv{A} \marr \menv \marr \dtypm{A}$ \\
\hline
\refsec{TODO} & \refthm{TODO} & $\mrec$ & $\typm{C} \marr \typm{C \arr C} \marr \typm{\nat} \marr \typm{C}$ \\
}
%% \begin{tabularx}{\textwidth}{ |c|c|c|X| }
%%   \hline
%%   \hline
%% \end{tabularx}
%% \hfill \break

When evaluating a function (a $\lam$ term),
return type of evaluation is a model-level function. This means that
we get a model value from the domain of the model function, which we
can subsequently extend the model environment with. Lucky for us, as
the recursive evaluation of the $\lam$ body requires a context extended
with just the type we need! Of course this is no coincidence, as it is
the reason why evaluation requires an environment model parameter in
the first place. The more interesting part of evaluating the function
is that the value we get (to extend the environment with) has been
weakened by an arbitrary $\Delta$! Therefore, we must also weaken the
model environment, by appealing to the monotonicity lemma for
environments (\reflem{monos}).


\begin{myproof}{
By induction on the neutral $\typn{A}$.
}

\begin{mycase}[Variable]
\begin{align*}
i   &: \typr{A} && \byass\\
\sigma  &: \menv && \byass\\
a  &: \dtypm{A} && \by{\lookup~\sigma~i}
\end{align*}
\end{mycase}

\begin{mycase}[Application]
\begin{align*}
f   &: \typn{A \arr B} && \byass\\
a   &: \typv{A} && \byass\\
\sigma  &: \menv && \byass\\
f'  &: \dtypm{A \arr B} && \ih{\cevaln~f~\sigma}\\
f'  &: \all{\Delta} \gdtypm{A} \marr \gdtypm{B} && \bydef\\
a'  &: \dtypm{A} && \ih{\cevalv~a~\sigma}\\
b   &: \dtypm{B} && \by{f~\emp~a'}
\end{align*}
\end{mycase}

\begin{mycase}[Primitive Recursion]
\begin{align*}
c_z  &: \typv{C} && \byass\\
c_s  &: \typv{C \arr C} && \byass\\
n    &: \typn{\nat} && \byass\\
\sigma  &: \menv && \byass\\
c_z' &: \dtypm{C} && \ih{\cevalv~c_z~\sigma}\\
c_s' &: \dtypm{C \arr C} && \ih{\cevalv~c_s~\sigma}\\
n'   &: \dtypm{\nat} && \ih{\cevaln~n~\sigma}\\
c    &: \dtypm{C} && \by{\el{\rec}~c_z'~c_s'~n'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mytheorem}


\section{Environment Reflection}

\todo[inline]{description and proof}


%% \begin{align*}
%% &\typm{A \arr B}& &\dfn \forall \Delta.~ \dren \marr \dtypm{A} \marr \dtypm{B} \\
%% &\typm{A}& &\dfn \typv{A}
%% \end{align*}



%% \begin{displaymath}
%%     \xymatrix{
%%           {\forall (v : \typv{A}) (\sigma : \denv)} \ar[dr] 
%%             \ar[r]
%%         & {\dtypm{A}} \ar[d]
%% \\      & {\exists (v' : \dtypv{A}). ~ [ \sigma ] v = v'} }
%% \end{displaymath}

\section{Related Work}

Our termination proof is a novel model-theoretic result, but it
does not solve the proof-theoretic version of the same problem.
Nevertheless, we view our solution as somewhere in between a largely
model theoretic, and proof theoretic semantics, as it is a syntactic
model (rather than HA or CCC).

\todo[inline]{formal version of Kripke model via renaming}
\todo[inline]{extension polymorphic lists}
\todo[inline]{correctness wrt contextual equiv on exprs}
\todo[inline]{Future work: state (via worlds), exceptions (via monad),
  dependent types}
\todo[inline]{reference morrison nbe formalization}

%% \acks

%% We would like to thank Andrew Cave for helping us understand subtle
%% issues related to context weakening when formalizing termination proofs. We would also
%% like to thank Darin Morrison for originally introducing us to the connection
%% between NbE and a Kripke model for intuitionistic logic.
%% This work was supported by NSF/CISE/CCF grant \#1320934.



\bibliographystyle{abbrvnat}
\bibliography{sbe}

\clearpage

\section*{\appendixname}
\appendix

\section{Evaluation}

\begin{theorem}[Evaluation]
\label{thm:eval}
$$
\fun{eval} : \type{A} \marr \menv \marr \dtypm{A}
$$

\begin{proof}

By induction on the expression $\type{A}$. This proof is standard and
we do not repeat it here for space reasons. However, part of the
insight of this paper is that is that what we call
\textit{canonical evaluation} (\refthm{mod:cevalv}), the intrinsic hereditary substitution
semantics, is essentially the same thing! To recover this proof,
replace instances of values and neutrals with expressions in the proof
of \refthm{mod:cevalv} and \refthm{mod:cevaln} from \refsec{vmod}.

\end{proof}

\end{theorem}

Because the model of natural numbers is just a natural number value,
the model of primitive recursion works basically the same way that
normalization of primitive recursion would work in the theory. The
main difference is that the arguments and return type are really
elements of the model. In particular, the successor branch for the
primitive recursion is a model function that we may simply apply to
other model values (i.e. the induction hypothesis).

\begin{lemma}[Model of Primitive Recursion]
\label{lem:rec}
$$
\mrec : \typm{C} \marr \typm{C \arr C} \marr \typm{\nat} \marr \typm{C}
$$

\begin{proof}

By induction on the natural number model value $\typm{\nat}$.
Definitionally, this reduces to induction on the natural number theory
value $\typv{\nat}$.

\begin{scase}[Zero]
\begin{align*}
c_z  &: \typm{C} && \byass
\end{align*}
\end{scase}

\begin{scase}[Successor]
\begin{align*}
c_z  &: \typm{C} && \byass\\
c_s  &: \typm{C \arr C} && \byass\\
n    &: \typv{\nat} && \byass\\
n    &: \typm{\nat} && \bydef\\
c    &: \typm{C} && \ih{\el{\fun{rec}}~c_z~c_s~n}\\
c_s  &: \all{\Delta} \gdtypm{C} \marr \gdtypm{C} && \bydef\\
c'   &: \typm{C} && \by{c_s~\emp~c}
\end{align*}
\end{scase}

\begin{scase}[Neutral]
\begin{align*}
c_z  &: \typm{C} && \byass\\
c_s  &: \typm{C \arr C} && \byass\\
n    &: \typn{\nat} && \byass\\
c_z' &: \typv{C} && \by{\fun{reify}~c_z}\\
c_s' &: \typv{C \arr C} && \by{\fun{reify}~c_s}\\
c'   &: \typn{C} && \by{\fun{rec}~c_z'~c_s'~n}\\
c''  &: \typm{C} && \by{\fun{reflect}~c'}
\end{align*}
\end{scase}

\end{proof}

\end{lemma}

\section{Reification}

Reification (\refthm{reify}) is the process of turning a model value into a theory
model. The model of natural numbers is the theory value, so their
reification is immediate. The interesting case is the reification of
functions. We need to somehow go from a higher-order model function to
a first-order theory value of function type. The model of functions
was specifically engineered to make it possible to weaken the domain
and codomain by an arbitrary $\Delta$ for exactly this case! A
function is reified by weakening by the type expected in the domain,
passing in a free variable of De Bruijn zero, then constructing a
lambda value from the reification of the result. However, the domain
of the model function a model value, so we must translate the variable
to an element of the model. Luckily, it is possible to
reflect (\reflem{reflect}) any neutral term (including variables),
so we must prove reflection mutually with reification.

\begin{theorem}[Reification]
\label{thm:reify}
$$
\fun{reify} : \typm{A} \marr \typv{A}
$$

\begin{proof}

By induction on the type $A$.

\begin{scase}[Natural numbers]
\begin{align*}
n  &: \typm{\nat} && \byass\\
n  &: \typv{\nat} && \bydef
\end{align*}
\end{scase}

\begin{scase}[Functions]
\begin{align*}
f &: \typm{A \arr B} && \byass\\
f &: \all{\Delta} \gdtypm{A} \marr \gdtypm{B} && \bydef\\
a &: \gatypm{A} && \ih{\reflect~(\con{var here})}\\
b &: \gatypm{B} && \by{f~(\emp, A)~a}\\
b' &: \gatypv{B} && \ih{\fun{reify}~b}\\
f' &: \typv{A \arr B} && \by{\lam b'}
\end{align*}
\end{scase}

\end{proof}

\end{theorem}

Note that we can only reflect neutrals. Values must instead be
evaluated (\refthm{mod:eval}), which requires a model of an
environment (\refdef{menv}) as an additional parameter that neutral reflection does
not need. The proof of reflection is straightforward and given explicitly
below. 

\begin{sublemma}[Neutral Reflection]
\label{lem:reflect}
$$
\reflect : \typn{A} \marr \typm{A}
$$

\begin{proof}

By induction on the type $A$.

\begin{slcase}[Natural numbers]
\begin{align*}
n  &: \typn{\nat} && \byass\\
n' &: \typv{\nat} && \by{\con{neut}~n}\\
n' &: \typm{\nat} && \bydef
\end{align*}
\end{slcase}

\begin{slcase}[Functions]
\begin{align*}
f &: \typn{A \arr B} && \byass\\
\Delta& && \byass\\
a  &: \gdtypm{A} && \byass\\
f' &: \gdtypn{A \arr B} && \by{\wknn{f}}\\
a' &: \gdtypv{A} && \ih{\fun{reify}~a}\\
b  &: \gdtypm{B} && \ih{\reflect~(f' \cdot a')}
\end{align*}
\end{slcase}

\end{proof}

\end{sublemma}


\section{Identity Model Environment}

The identity model environment is a mapping from each variable in a
context, to the same variable but as a model value. Essentially, the
proof reflects each variable of the context, but it must also appeal
to model environment monotonicity (\reflem{mod:monos}) to weaken the
previously built identity model environment.

\begin{theorem}[Identity Model Environment]
\label{thm:midenv}
$$
\midenv : \all{\Gamma} \gmenv{\Gamma}
$$

\begin{proof}
By induction on the context $\Gamma$.

\begin{scase}[Empty Context]
\begin{align*}
u &: \top && \bytri\\
u &: \cmenv{\emp}{\emp} && \bydef
\end{align*}
\end{scase}

\begin{scase}[Context extension]
\begin{align*}
\Gamma& && \byass\\
A& && \byass\\
\sigma  &: \cmenv{\Gamma}{\Gamma} && \ih{\midenv~\Gamma}\\
\sigma' &: \cmenv{\Gamma}{(\Gamma, A)} && \by{\monos~(\emp, A)~\sigma}\\
x    &: \gatypm{A} && \by{\reflect~(\var~\here)}\\
\sigma'' &: \cmenv{(\Gamma, A)}{(\Gamma, A)} && \by{\sigma', x}
\end{align*}
\end{scase}

\end{proof}

\end{theorem}


As mentioned above, we need environment model monotonicity
to define the $\lam$ case of \refthm{mod:eval}. Environment model
monotonicity is essentially a mapping of a value model
monotonicity (\reflem{mod:mono}) across all inhabitants of the
environment model.

\begin{lemma}[Environment Model Monotonicity]
\label{lem:monos}
$$
\monos : \all{\Delta} \gmenv{\Xi} \marr \gmenv{(\Xi, \Delta)}
$$

\begin{proof}
By induction on the context $\Gamma$.

\begin{lcase}[Empty Context]
\begin{align*}
\Delta& && \byass\\
u &: \top && \byass\\
u &: \cmenv{\emp}{(\Xi, \Delta)} && \bydef
\end{align*}
\end{lcase}

\begin{lcase}[Context extension]
\begin{align*}
\Delta& && \byass\\
\sigma &: \gmenv{\Xi} && \byass\\
x    &: \xtypm{A} && \byass\\
\sigma'  &: \gmenv{(\Xi, \Delta)} && \ih{\monos~\Delta~\sigma}\\
x'   &: \xdtypm{A} && \by{\mono~\Delta~x}\\
\sigma'' &: \cmenv{(\Gamma, A)}{(\Xi, \Delta)} && \by{\sigma', x'}
\end{align*}
\end{lcase}

\end{proof}

\end{lemma}

The model monotonicity lemma is basically a version of weakening (of
theory values) lifted to values in the model. 

\begin{lemma}[Value Model Monotonicity]
\label{lem:mod:mono}
$$
\mono : \all{\Delta} \typm{A} \marr \gdtypm{A}
$$

\begin{proof}

By case analysis of the type $A$.

\begin{scase}[Natural numbers]
\begin{align*}
\Delta& && \byass\\
n  &: \typm{\nat} && \byass\\
n  &: \typv{\nat} && \bydef\\
n' &: \gdtypv{\nat} && \by{\wknv{n}}\\
n' &: \gdtypm{\nat} && \bydef
\end{align*}
\end{scase}

\begin{scase}[Functions]
\begin{align*}
\Delta& && \byass\\
f  &: \typm{A \arr B} && \byass\\
\Xi& && \byass\\
a  &: \el{(\Gamma, \Delta), \Xi \vdash A} && \byass\\
a  &: \el{\Gamma, (\Delta, \Xi) \vdash A} && \by{associativity}\\
f  &: \all{\Phi} \gftypm{A} \marr \gftypm{B} && \bydef\\
b  &: \el{\Gamma, (\Delta, \Xi) \vdash B} && \by{f~(\Delta,\Xi)~a}\\
b  &: \el{(\Gamma, \Delta), \Xi \vdash B} && \by{associativity}
\end{align*}
\end{scase}

\end{proof}

\end{lemma}

\section{Normalization by Hereditary Substitution}

\begin{theorem}[Normalization by Hereditary Substitution]
\label{thm:mod:nbs}
$$
\nbs : \type{A} \marr \typv{A}
$$

\begin{proof}
\begin{align*}
&\nbs ~ \zero &&\dfn&& \zero\\
&\nbs ~ (\suc~n) &&\dfn&& \suc ~ (\nbs~n)\\
&\nbs ~ (\lam b) &&\dfn&& \lam (\nbs~b)\\
&\nbs ~ (\var~i) &&\dfn&& \neut ~ (\var~i)\\
&\nbs ~ (f~\app~a) &&\dfn&& \abs ~ (\nbs~f) ~ (\nbs~a)\\
&\nbs ~ (\rec~c_z~c_s~n) &&\dfn&& \rbs~(\nbs~c_z)~(\nbs~c_s)~(\nbs~n)
\end{align*}
\end{proof}

\end{theorem}

\begin{lemma}[Application by Hereditary Substitution]
\label{thm:mod:abs}
$$
\abs : \typv{A \arr B} \marr \typv{A} \marr \typv{B}
$$

\begin{proof}
\begin{align*}
&\abs ~ (\lam b) ~ a &&\dfn&& \sbe~b~(\idenv~\Gamma, a)\\
&\abs ~ (\neut~f) ~ a &&\dfn&& \neut~(f~\app~a)
\end{align*}
\end{proof}

\end{lemma}

\todo[inline]{Identity Environment description and proof}

\begin{lemma}[Primitive Recursion by Hereditary Substitution]
\label{thm:mod:rbs}
$$
\rbs : \typv{C} \marr \typv{C \arr C} \marr \typv{\nat} \marr \typv{C}
$$

\begin{proof}
\begin{align*}
&\rbs ~ c_z ~ c_s ~ \zero &&\dfn&& c_z\\
&\rbs ~ c_z ~ c_s ~ (\suc~n) &&\dfn&& \abs~c_s~(\rbs~c_z~c_s~n)\\
&\rbs ~ c_z ~ c_s ~ (\neut~n) &&\dfn&& \neut~(\rec~c_z~c_s~n)
\end{align*}
\end{proof}

\end{lemma}


\clearpage

\begin{figure}
\caption{
BNF grammar for \textit{types} and \textit{contexts}. 
Expressions, values, and neutrals
are not represented by a BNF grammar. Instead, they are defined by
an intrinsically typed representation, rather than a BNF grammar and
an extrinsic typing relation over said grammar.
}
\begin{align*}
A, B, C &::= \nat ~ | ~ A \arr B \\
\Gamma, \Delta, \Xi, \Phi &::= \emp ~ | ~ \Gamma , A
\end{align*}
\label{fig:gram}
\end{figure}

\begin{figure}
\caption{
Intrinsic typing of De Bruijn \textit{variables}.
The intrinsically typed variables act as proofs that the type
parameter of the judgment appears in the context parameter of the
judgement.
}
$$
\infer
  [\con{here}]
  {\ctypr{A}{A}}
{
}
\qquad
\infer
  [\con{there} ~ i]
  {\ctypr{B}{A}}
{
  (i : \typr{A})
}
$$
\label{fig:typr}
\end{figure}

\begin{figure}
\caption{
Intrinsic typing of \textit{expressions} for G{\"o}del's System T. The
intrinsically typed expressions act as proofs that the expression
represented by the proof term is well typed.
}
$$
\infer
  [\con{zero}]
  {\type{\nat}}
{}
\qquad
\infer
  [\con{suc} ~ n]
  {\type{\nat}}
{
  (n : \type{\nat})
}
$$

$$
\infer
  [\lam b]
  {\type{A \arr B}}
{
  (b : \ctype{A}{B})
}
\qquad
\infer
  [\fun{var} ~ i]
  {\type{A}}
{
  (i : \typr{A})
}
$$

$$
\infer
  [f \app a]
  {\type{B}}
{
  (f : \type{A \arr B})
  &
  (a : \type{A})
}
$$

$$
\infer
  [\fun{rec} ~ n ~ c_z ~ c_s]
  {\type{C}}
{
  (n : \type{\nat})
  &
  (c_z : \type{C})
  &
  (c_s : \type{C \arr C})
}
$$
\label{fig:type}
\end{figure}

\begin{figure}
\caption{
Intrinsic typing of \textit{values} (canonical terms) for G{\"o}del's System T.
The intrinsically typed values act as proofs that the value
represented by the proof term is well typed. The grammar of values
also includes all neutral terms.
}
$$
\infer
  [\con{zero}]
  {\typv{\nat}}
{}
\qquad
\infer
  [\con{suc} ~ n]
  {\typv{\nat}}
{
  (n : \typv{\nat})
}
$$

$$
\infer
  [\lam b]
  {\typv{A \arr B}}
{
  (b : \ctypv{A}{B})
}
\qquad
\infer
  [\fun{neut} ~ a]
  {\typv{A}}
{
  (a : \typn{A})
}
$$
\label{fig:typv}
\end{figure}

\begin{figure}
\caption{
Intrinsic typing of \textit{neutrals} (variables and elimination rules) 
for G{\"o}del's System T.
The intrinsically typed neutrals act as proofs that the neutral
represented by the proof term is well typed.
}

$$
\infer
  [\fun{var} ~ i]
  {\typn{A}}
{
  (i : \typr{A})
}
$$

$$
\infer
  [f \app a]
  {\typn{B}}
{
  (f : \typn{A \arr B})
  &
  (a : \typv{A})
}
$$

$$
\infer
  [\fun{rec} ~ n ~ c_z ~ c_s]
  {\typn{C}}
{
  (n : \typn{\nat})
  &
  (c_z : \typv{C})
  &
  (c_s : \typv{C \arr C})
}
$$
\label{fig:typn}
\end{figure}

\end{document}
