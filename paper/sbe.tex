\documentclass[runningheads,a4paper]{llncs}
\setcounter{tocdepth}{3}
\usepackage{etex} % trick to get xypic to load
\usepackage{proof}
\usepackage{xifthen}

\usepackage{todonotes}
\usepackage{amsmath}
%% \usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{url}
\usepackage{bbm}
\usepackage[greek,english]{babel}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{autofe}
\usepackage{stmaryrd}
\usepackage{enumitem}
\usepackage[all]{xy}

\usepackage{tabularx}
\renewcommand{\arraystretch}{1.5} % more table padding

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}

\usepackage{fancyvrb}

\usepackage[labelfont=bf]{caption}

\newtheorem{defin}{Definition}

\spnewtheorem{mydefinition'}{Definition}{\bfseries}{\itshape}
\spnewtheorem{mytheorem'}{Theorem}{\bfseries}{\rmfamily}
\spnewtheorem{mylemma'}{Lemma}{\bfseries}{\rmfamily}
\spnewtheorem*{mycase}{Case}{\bfseries}{\rmfamily}
\spnewtheorem*{myproof'}{Proof}{\itshape}{\rmfamily}

\newenvironment{mydefinition}[3]
{ \begin{mydefinition'}[#1] \label{def:#2}
  \hfill\break
  #3
}
{ \end{mydefinition'} }

\newenvironment{myproof}[1]
{ \begin{myproof'} \ifthenelse{\isempty{#1}}{}{\textit{#1}} }
{ \myqed \end{myproof'} }

\newenvironment{mytheorem}[4]
{ \begin{mytheorem'}[#1] \label{thm:#2}
  $$#3$$

  \ifthenelse{\isempty{#4}}{}{
  \begingroup \small
  \begin{tabularx}{\textwidth}{ |c|c|c|X| }
    \hline #4 \hline
  \end{tabularx}
  \hfill \break  
  \endgroup
  }
}
{ \end{mytheorem'} }

\newenvironment{mylemma}[4]
{ \begin{mylemma'}[#1] \label{lem:#2}
  $$#3$$

  \ifthenelse{\isempty{#4}}{}{
  \begingroup \small
  \begin{tabularx}{\textwidth}{ |c|c|c|X| }
    \hline #4 \hline
  \end{tabularx}
  \hfill \break  
  \endgroup
  }
}
{ \end{mylemma'} }

\newcommand{\refdef}[1]{Definition \ref{def:#1}}
\newcommand{\refthm}[1]{Theorem \ref{thm:#1}}
\newcommand{\reflem}[1]{Lemma \ref{lem:#1}}

\newcommand{\reffig}[1]{Figure \ref{fig:#1}}
\newcommand{\refapp}[1]{Appendix \ref{sec:#1}}
\newcommand{\refsec}[1]{Section \ref{sec:#1}}
\newcommand{\refparte}[1]{Part$_E$ \ref{parte:#1}}
\newcommand{\refparti}[1]{Part$_I$ \ref{parti:#1}}

\def\myqed{\nobreak\hfil
\penalty50\hskip1em\null\nobreak\hfil\squareforqed
\parfillskip=0pt\finalhyphendemerits=0\endgraf}

\def\cross{\times}
\def\dfn{\triangleq}
\def\dfun{\mapsto}
\def\bigstep{\Downarrow}
\def\arr{\supset}
\def\marr{\rightarrow}
\def\app{\cdot}
\def\lam{\lambda}
\def\nat{\mathbb{N}}
\def\emp{\emptyset}

\def\here{\con{here}}
\def\there{\con{there}}

\def\var{\con{var}}
\def\zero{\con{zero}}
\def\suc{\con{suc}}
\def\neut{\con{neut}}

\def\mrec{\el{\fun{rec}}}
\def\mrecT{\typm{C} \marr \typm{C \arr C} \marr \typm{\nat} \marr \typm{C}}

\def\rec{\fun{rec}}

\def\rbs{\fun{rbs}}
\def\rbsT{\typv{C} \marr \typv{C \arr C} \marr \typv{\nat} \marr \typv{C}}

\def\abs{\fun{abs}}
\def\absT{\typv{A \arr B} \marr \typv{A} \marr \typv{B}}

\def\reify{\fun{reify}}
\def\reifyT{\typm{A} \marr \typv{A}}

\def\reflectn{\fun{reflect}^\con{N}}
\def\reflectnT{\typn{A} \marr \typm{A}}
\def\reflect{\reflectn}

\def\reflecte{\fun{reflect}^\con{S}}
\def\reflecteT{\all{\Delta} \env \marr \menv}

\def\reflectc{\fun{reflect}^\con{C}}
\def\reflectcT{\all{\Gamma} \gmenv{\Gamma}}

\def\idenv{\sigma_\fun{id}}


\def\mono{\fun{mono}^\con{V}}
\def\monoT{\all{\Delta} \typm{A} \marr \gdtypm{A}}

\def\monos{\fun{mono}^\con{S}}
\def\monosT{\all{\Delta} \gmenv{\Xi} \marr \gmenv{\Xi, \Delta}}

\def\eval{\fun{eval}^\con{E}}
\def\evalT{\type{A} \marr \menv \marr \dtypm{A}}

\def\cevalv{\fun{eval}^\con{V}}
\def\cevalvT{\typv{A} \marr \menv \marr \dtypm{A}}

\def\cevaln{\fun{eval}^\con{N}}
\def\cevalnT{\typn{A} \marr \menv \marr \dtypm{A}}

\def\lookup{\fun{lookup}}

\def\nbe{\fun{nbe}}
\def\nbeT{\type{A} \marr \typv{A}}

\def\sbe{\fun{sbe}}
\def\sbeT{\typv{A} \marr \env \marr \dtypv{A}}


\def\nsbe{\fun{nsbe}}

\def\nbs{\fun{nbs}}
\def\nbsT{\type{A} \marr \typv{A}}

\def\bydef{(\textit{definition})}
\def\byass{(\textit{assumption})}
\def\bywkn{(\textit{weakening})}
\def\bytri{(\textit{trivial})}
\newcommand{\ih}[1]{(\textit{i.h.}~ #1)}
\newcommand{\by}[1]{(#1)}

\newcommand{\turn}[1]{\vdash^\con{#1}}

\newcommand{\hsubn}[2]{[\sigma]#1=^\con{N}#2}
\newcommand{\hsub}[2]{[\sigma]#1=^\con{V}#2}
\newcommand{\hsubext}[3]{[\sigma, #1]#2=^\con{V}#3}

\newcommand{\ascribe}[2]{(#1 : #2)}
\newcommand{\all}[1]{\forall#1.~}
\newcommand{\ex}[1]{\exists#1.~}

\newcommand{\el}[1]{\llbracket #1 \rrbracket}
\newcommand{\els}[1]{\llbracket ~ #1 ~ \rrbracket}

\def\wknet{\fun{wkn}^\con{E}}
\newcommand{\wkne}[1]{\wknet ~ \Delta ~ #1}

\def\wknvt{\fun{wkn}^\con{V}}
\def\wknvT{\all{\Delta} \typv{A} \marr \gdtypv{A}}
\newcommand{\wknv}[1]{\wknvt ~ \Delta ~ #1}

\def\wknnt{\fun{wkn}^\con{N}}
\def\wknnT{\all{\Delta} \typn{A} \marr \gdtypn{A}}
\newcommand{\wknn}[1]{\wknnt ~ \Delta ~ #1}

\newcommand{\con}[1]{\textmd{#1}}
\newcommand{\fun}[1]{\textmd{#1}}

\newcommand{\typm}[1]{\els{\Gamma \vdash #1}}
\newcommand{\dtypm}[1]{\els{\Delta \vdash #1}}
\newcommand{\xtypm}[1]{\els{\Xi \vdash #1}}
\newcommand{\xdtypm}[1]{\els{\Xi, \Delta \vdash #1}}
\newcommand{\gdtypm}[1]{\els{\Gamma, \Delta \vdash #1}}
\newcommand{\gftypm}[1]{\els{\Gamma, \Phi \vdash #1}}
\newcommand{\gatypm}[1]{\els{\Gamma, A \vdash #1}}
\newcommand{\ctypm}[2]{\els{\Gamma , #1 \vdash #2}}

\newcommand{\type}[1]{\Gamma \turn{E} #1}
\newcommand{\dtype}[1]{\Delta \turn{E} #1}
\newcommand{\gdtype}[1]{\Gamma, \Delta \turn{E} #1}
\newcommand{\gatype}[1]{\Gamma, A \turn{E} #1}
\newcommand{\ctype}[2]{\Gamma , #1 \turn{E} #2}

\newcommand{\typv}[1]{\Gamma \turn{V} #1}
\newcommand{\dtypv}[1]{\Delta \turn{V} #1}
\newcommand{\gdtypv}[1]{\Gamma, \Delta \turn{V} #1}
\newcommand{\gatypv}[1]{\Gamma, A \turn{V} #1}
\newcommand{\ctypv}[2]{\Gamma , #1 \turn{V} #2}

\newcommand{\typn}[1]{\Gamma \turn{N} #1}
\newcommand{\dtypn}[1]{\Delta \turn{N} #1}
\newcommand{\gdtypn}[1]{\Gamma, \Delta \turn{N} #1}
\newcommand{\gatypn}[1]{\Gamma, A \turn{N} #1}
\newcommand{\ctypn}[2]{\Gamma , #1 \turn{N} #2}

\newcommand{\typr}[1]{\Gamma \turn{R} #1}
\newcommand{\dtypr}[1]{\Delta \turn{R} #1}
\newcommand{\ctypr}[2]{\Gamma , #1 \turn{R} #2}

\def\menv{\dmenv{\Gamma}}
\def\env{\denv{\Gamma}}
\def\enve{\Delta \turn{E} \Gamma}
\newcommand{\dmenv}[1]{\els{\Delta \vdash #1}}
\newcommand{\denv}[1]{\Delta \turn{V} #1}
\newcommand{\gmenv}[1]{\els{#1 \vdash \Gamma}}
\newcommand{\genv}[1]{#1 \turn{V} \Gamma}
\newcommand{\cmenv}[2]{\els{#2 \vdash #1}}
\newcommand{\cenv}[2]{#2 \turn{V} #1}


\def\mytitle{
Hereditary Substitution
\\by Canonical Evaluation
}

\begin{document}

\mainmatter

\title{\mytitle (SbE)}
\subtitle{[Draft under consideration for publication in ESOP 2015]}
\titlerunning{\mytitle}

\author{Larry Diehl \and Tim Sheard}

\institute{Portland State University\\
\email{\{ldiehl,sheard\}@cs.pdx.edu}}

\maketitle

\begin{abstract}

Hereditary substitution is a version of substitution that works with canonical terms. 
Substituting into a canonical term may temporarily create a $\beta$-redex.
Hereditary substitution immediately evaluates the redex to once again
obtain a canonical term.
Termination of hereditary substitution has
primarily been studied \textit{proof-theoretically}. However,
formal proof-theoretic termination arguments of hereditary substitution have
trouble scaling to systems with inductive types, such as
G{\"o}del's System T.

We present a \textit{model-theoretic}
termination argument of hereditary substitution that scales to
systems with inductive types. Specifically, we adapt some of the techniques
used in formalizing
Normalization by Evaluation (NbE). Much of the existing NbE machinery can be reused. In some sense, we merely point out
a beautiful coincidence: Canonical evaluation (evaluation
from NbE, but defined on canonical terms) is a
terminating model-theoretic definition of hereditary substitution.
All of our work has been verified by Agda.
\footnote{\raggedright{The accompanying source code can be found at
{\tt https://github.com/larrytheliquid/sbe}}}

\keywords{
Hereditary substitution; normalization by evaluation; termination;
type theory; formalization.
}

\end{abstract}

\section{Introduction}
\label{sec:intro}

Normalization by Evaluation (NbE)~\cite{berger,coquandnbe,danvy} is a model-theoretic
technique for defining the semantics of a $\lambda$-calculus. For
example, normalization for a total $\lambda$-calculus with inductive
types (such as G{\"o}del's System T~\cite{systemt}) can be defined by first
evaluating a syntactic expression (possibly containing $\beta$-redexes) to a
semantic value of a Kripke model~\cite{kripkeoriginal,kripkemodel}, and then reifying the result to a syntactic value
(not containing any $\beta$-redexes).

\begin{displaymath}
    \xymatrix{
          {\forall (e : A)} 
          \ar[dr]_{\fun{norm}}
          \ar[r]^{\eval}
        & {\els{A}}
          \ar[d]^{\large{\fun{reify}}}
\\      & \exists (v : A) }
\end{displaymath}

NbE is especially convenient for formalizing the semantics of total
$\lambda$-calculi in dependently typed languages (such as
Coq~\cite{coq08}, Agda~\cite{norell2007towards}, or Idris~\cite{brady2011idris}), because the
proof of termination of the semantics is \textit{implicit} in its
definition. In other words, normalization can be defined as a total
function within a language based on
Martin-L{\"o}f Type Theory~\cite{martinintuitionistic,martin1975intuitionistic,nordstrom1990programming}.
In contrast, formalizing the semantics of expressions as a
relation (e.g. a small or big-step relation), or as a
coinductive function~\cite{coinductivenbe}, requires the additional overhead
of supplying an \textit{explicit}
termination proof \textit{a posteriori} using techniques such as
logical relations~\cite{plotkinlogrel}.

In a standard type theory \textit{expressions} are emphasized and
their semantics is defined directly. Alternatively, a
\textit{canonical type theory} emphasizes \textit{values} (canonical terms) and defines
the semantics of expressions in terms of hereditary substitution of
values (for example, see \refapp{nbs}). 
Values are not closed under ordinary substitution, because a
substitution can introduce a $\beta$-redex. Hereditary substitution
fixes this problem by reducing whenever a $\beta$-redex is created as
the result of substitution. But, it is not easy to show that
traditional proof-theoretic definitions of hereditary substitution 
terminate (for a suitably complex $\lambda$-calculus, see
\refsec{proof-theoretic} below)
in dependently typed languages.

\textbf{Our contribution} is adapting NbE to canonical terms, giving us a model-theoretic
definition of hereditary substitution. We call this technique
``Hereditary Substitution by Canonical Evaluation (SbE)''. Defining
SbE requires us to introduce novel definitions, but we also get to
reuse the model from NbE, as well as some of its definitions. SbE is
defined by \textit{canonically evaluating} a syntactic value to a
semantic value (of a Kripke model), and then reifying back to a syntactic value.

\begin{displaymath}
    \xymatrix{
          \forall{\ascribe{v}{A}, \sigma}
          \ar[dr]_{\fun{hsub}}
          \ar[r]^{\cevalv}
        & {\els{A}}
          \ar[d]^{\large{\fun{reify}}}
\\      & \exists{\ascribe{v'}{A}} }
\end{displaymath}

SbE is a functional definition of hereditary substitution that
contains an intrinsic termination proof, just like the functional
definition of normalization that you get from NbE. Thus, SbE is
amenable to formalization, allowing canonical type theory for
$\lambda$-calculi with inductive types to be defined in dependent type
theory. For simplicity, we use G{\"o}del's System T for our examples
in this paper, but SbE scales to systems with parameterized inductive
types (such as lists or trees) for the same reasons that NbE does.

\subsection{Proof Theoretic Semantics}
\label{sec:proof-theoretic}

Hereditary substitution has historically been studied in the context
of proof-theoretic semantics. A proof-theoretic semantics takes
syntactic inputs directly to syntactic outputs, without going through
an intermediate semantic model. Additionally, a proof-theoretic
termination proof (which can be implicit in the semantics or given explicitly) is completely
syntactic (i.e. it does not use a logical relation).
Formalizing this approach in
dependently typed languages has been limited to simple calculi.
For example, Keller and Altenkirch~\cite{keller} show how to formalize the
semantics of the STLC in Agda using syntactic hereditary substitution.
The termination of the hereditary substitution function is witnessed
by lexicographic induction on terms and types, but this approach does
not scale to $\lambda$-calculi with inductive types.

An advantage of the syntactic approach to hereditary substitution is
that it demands less from the metalanguage than a semantic
approach (i.e. the metalanguage
function space is not needed to construct a model). A disadvantage of
the syntactic approach is that exposing the lexicographic termination
argument requires changing the structure of values, i.e. requiring
values to be in spine form.

\subsection{Outline}

After a brief discussion about our notation, the rest of the paper is
structured as follows:

\begin{itemize}
\item{\bf{\refsec{overview}}}
We review the model and theorems used by NbE, and explain the
definition of NbE (and its implicit termination proof). Then, we present the
novel definition of SbE, in which we reuse the model and some theorems
from NbE. Finally, we compare and contrast SbE with NbE.

\item{\bf{\refsec{ceval}}}
We present the novel definition of canonical evaluation. In NbE,
evaluation takes a syntactic expression and a semantic environment to
a semantic value. Canonical evaluation is like evaluation, except it
operates on values instead of expressions. In SbE, canonical evaluation
takes a syntactic value and a semantic environment to
a semantic value.

\item{\bf{\refsec{reflecte}}}
We present the novel definition of environment reflection. Because
hereditary substitution already has a syntactic environment parameter
(the ``substitution'' to be applied to the variables of the syntactic
value that we are hereditarily substituting into), we must reflect that
syntactic environment as a semantic environment so that we may use it
as an argument of canonical evaluation.

\item{\bf{\refsec{related}}}
We discuss related and future work. In particular, we compare and contrast
proof-theoretic and model-theoretic hereditary substitution in more
detail. We also point out how SbE (model-theoretic
hereditary substitution) can be adapted from NbE to calculi with
inductive types. In contrast, adapting proof-theoretic hereditary
substitution to calculi with inductive types has been problematic.
\end{itemize}

\subsection{Notation}

We define types and contexts for G{\"o}del's System T using a standard
BNF grammar in \reffig{gram}. However, we use intrinsically typed
terms instead of defining a grammar for terms and an extrinsic
typing relation. Below is an example of the standard extrinsic typing
of expressions.

$$
e ::= ... ~ | ~ \con{zero} ~ | ~ \con{suc} ~ n ~ | ~ ...
$$

$$
\infer
  [\nat\con{-I}_2]
  {\Gamma \turn{E} \con{suc} ~ n : \nat}
{
  \Gamma \turn{E} n : \nat
}
$$

Instead, we use the proof terms of our typing relation as
intrinsically typed terms (combining both definitions above into the
single definition below).

$$
\infer
  [\con{suc} ~ n]
  {\type{\nat}}
{
  (n : \type{\nat})
}
$$

We label each premise with a variable to
the left of a colon, and the name of the typing rule shows how to use
it as a proof term by applying it to the premise labels. In other
words, the labels represent the derivations of the premises.

The letter appearing as the superscript to the turnstyle is part of
the name of each intrinsic typing judgment. For example, $\turn{E}$
types expressions in \reffig{type}, $\turn{V}$ types values in
\reffig{typv}, and $\turn{N}$ types neutrals in \reffig{typn}.

Finally, we have taken care to ensure that all of our constructions
are easily formalizable. For this reason, we
use De Bruijn variables~\cite{debruijn}. For example, our typing rule
for functions does not explicitly bind its variable.

$$
\infer
  [\lam b]
  {\type{A \arr B}}
{
  (b : \ctype{A}{B})
}
$$

Additionally, proof that a (De Bruijn) variable of a particular type
exists in the context is given by the judgment $\turn{R}$ in
\reffig{typr}. Mentioning a variable in a term thus requires evidence
that the variable judgment is satisfied.

$$
\infer
  [\fun{var} ~ i]
  {\type{A}}
{
  (i : \typr{A})
}
$$

\begin{figure}[t!]
\caption{
BNF grammar for \textit{types} and \textit{contexts}. 
Expressions, values, and neutrals
are not represented by a BNF grammar. Instead, they are defined by
an intrinsically typed representation, rather than a BNF grammar and
an extrinsic typing relation over said grammar.
}
\begin{align*}
A, B, C &::= \nat ~ | ~ A \arr B \\
\Gamma, \Delta, \Xi, \Phi &::= \emp ~ | ~ \Gamma , A
\end{align*}
\label{fig:gram}
\end{figure}

\begin{figure}[t!]
\caption{
Intrinsic typing of De Bruijn \textit{variables}.
The intrinsically typed variables act as proofs that the type
parameter of the judgment appears in the context parameter of the
judgment.
}
$$
\infer
  [\con{here}]
  {\ctypr{A}{A}}
{
}
\qquad
\infer
  [\con{there} ~ i]
  {\ctypr{B}{A}}
{
  (i : \typr{A})
}
$$
\label{fig:typr}
\end{figure}

\begin{figure}[t!]
\caption{
Intrinsic typing of \textit{expressions} for G{\"o}del's System T. The
intrinsically typed expressions act as proofs that the expression
represented by the proof term is well typed.
}
$$
\infer
  [\con{zero}]
  {\type{\nat}}
{}
\qquad
\infer
  [\con{suc} ~ n]
  {\type{\nat}}
{
  (n : \type{\nat})
}
$$

$$
\infer
  [\lam b]
  {\type{A \arr B}}
{
  (b : \ctype{A}{B})
}
\qquad
\infer
  [\fun{var} ~ i]
  {\type{A}}
{
  (i : \typr{A})
}
$$

$$
\infer
  [f \app a]
  {\type{B}}
{
  (f : \type{A \arr B})
  &
  (a : \type{A})
}
$$

$$
\infer
  [\fun{rec} ~ n ~ c_z ~ c_s]
  {\type{C}}
{
  (n : \type{\nat})
  &
  (c_z : \type{C})
  &
  (c_s : \type{C \arr C})
}
$$
\label{fig:type}
\end{figure}

\section{Overview of NbE and SbE}
\label{sec:overview}

First we review why the proofs of termination of naive definitions of
normalization and hereditary substitution fail, and then we provide a
high-level overview of theorems and definitions necessary to define NbE
and SbE (which intrinsically terminate, unlike the naive definitions).
Finally, we discuss the similarities and differences between NbE and
SbE.
Henceforth, the development will proceed in a top-down manner.
Each theorem comes in four parts:

\begin{enumerate}
\item{The statement of the theorem.}
\item{A table of lemmas that the theorem depends on in its proof, and
  references to where proofs of the lemmas can be found.}
\item{A high-level discussion of the theorem and its proof.}
\item{The low-level details of the proof, sometimes interspersed with
  high-level explanations of how it works.}
\end{enumerate}

Preexisting proofs that we reuse from the NbE literature can be found
in the appendices, while novel proofs appear in the body of the paper.

\subsection{Termination Issues with Naive Definitions}

When defining normalization and hereditary substitution, the
main problem preventing an obvious termination
argument by structural induction is the lack of
an inductive hypothesis in the function application case.

\paragraph{Naive Normalization}
Consider the application case in the definition of strong normalization
below, given as a big-step binary relation between expressions. Below
``here'' refers to De Bruijn index zero from \reffig{typr}.

$$
\infer
  []{f \app a \bigstep {b'}}
{
  f \bigstep \lam b
  &
  a \bigstep a'
  &
  [a'/\con{here}]b \bigstep b'
}
$$

After evaluating the function to a lambda, we need to
substitute the argument into the lambda body. This may introduce
new $\beta$-redexes, so we must evaluate again but
there is no obvious termination measure to justify this. Above, we have
already appealed to the inductive hypothesis for the two subterms $f$
(the function) and $a$ (its argument), and there is no inductive
hypothesis for the function $\lambda$-body $b$. 

\paragraph{Naive Hereditary Substitution}
Consider the application case in the definition of hereditary substitution
below, given as a ternary relation between an input value, a mapping from
variables to values ($\sigma$), and a resulting value. Note that we
actually have two mutually defined relations, one for substituting
into a value and producing a new value ($\hsub{v}{v'}$), and another
for substituting into neutral but also producing a value
($\hsubn{n}{v}$).

$$
\infer
   []{\hsubn{(f \app a)}{b'}}
{
  \hsubn{f}{\lam b}
  &
  \hsub{a}{a'}
  &
  \hsubext{a'}{b}{b'}
}
$$

This relation is not obviously terminating for the same reason as
normalization. We have inductive hypotheses for substituting into the
function and substituting into the argument, but there is no inductive hypothesis for
substituting into the $\lambda$-body.

\begin{figure}[t!]
\caption{
Intrinsic typing of \textit{values} (canonical terms) for G{\"o}del's System T.
The intrinsically typed values act as proofs that the value
represented by the proof term is well typed. The grammar of values
also includes all neutral terms (see \reffig{typn}).
}
$$
\infer
  [\con{zero}]
  {\typv{\nat}}
{}
\qquad
\infer
  [\con{suc} ~ n]
  {\typv{\nat}}
{
  (n : \typv{\nat})
}
$$

$$
\infer
  [\lam b]
  {\typv{A \arr B}}
{
  (b : \ctypv{A}{B})
}
\qquad
\infer
  [\fun{neut} ~ a]
  {\typv{A}}
{
  (a : \typn{A})
}
$$
\label{fig:typv}
\end{figure}

\begin{figure}[t!]
\caption{
Intrinsic typing of \textit{neutrals} (variables and elimination rules) 
for G{\"o}del's System T.
The intrinsically typed neutrals act as proofs that the neutral
represented by the proof term is well typed.
}

$$
\infer
  [\fun{var} ~ i]
  {\typn{A}}
{
  (i : \typr{A})
}
$$

$$
\infer
  [f \app a]
  {\typn{B}}
{
  (f : \typn{A \arr B})
  &
  (a : \typv{A})
}
$$

$$
\infer
  [\fun{rec} ~ n ~ c_z ~ c_s]
  {\typn{C}}
{
  (n : \typn{\nat})
  &
  (c_z : \typv{C})
  &
  (c_s : \typv{C \arr C})
}
$$
\label{fig:typn}
\end{figure}

\subsection{The Model}

The naive definition of
normalization is defined in one phase, going directly from syntactic
expressions to syntactic values. In contrast, NbE is defined in two
phases. The first (called ``evaluation'') phase goes from syntactic expressions to semantic
values (of a Kripke model). The second phase (called ``reification'')
goes from semantic values to syntactic values. In the naive
definition, normalization (producing a syntactic value) is a large
definition given by case analysis over all syntactic forms of
expressions. In NbE, evaluation (producing a semantic value) is a
large definition given by case analysis over all syntactic forms of
expressions, while reification is a small definition given only by
case analysis over the types of semantic values.

NbE breaks up normalization into two phases (evaluation into the model
and reification back out of it) so that both phases can be defined
in a structurally terminating way. There are no termination issues
when defining reification (the smaller phase). However, evaluation
(the larger phase) must be defined by case analysis over all
expressions. Recall that the problematic
case in the definition of normalization is function application.
The definition of the
model below makes it possible to define the function application case
of evaluation in a structurally terminating way.

\begin{mydefinition}{Semantic Values}{mval}
{
The model of values $\typm{A}$ denotes a set (a type in the
metalanguage), and it is defined inductively on the structure
of (object language) types ($A$). We refer to any member of the model
of values as a ``semantic value''.
}

\begin{mycase}[Natural numbers]
$$
\typm{\nat} \dfn \typv{\nat}
$$
Syntactic natural number values are also semantic natural numbers
values.
\end{mycase}

\begin{mycase}[Functions]
$$
\typm{A \arr B} \dfn \all{\Delta} \gdtypm{A} \marr \gdtypm{B}
$$

The model of functions is a function in the metalanguage.
The semantic function takes a weakened semantic value (whose type is
the domain of the function) as an argument, and produces a
weakened semantic value (whose type is the codomain of the
function). Both the input and output values of the model function are
weakened by some arbitrary context $\Delta$, which can be empty.
\footnote{
In a true Kripke model the function case includes an accessibility relation
between contexts (or ``worlds''), allowing the semantic function domain and codomain to
be scoped under an arbitrary context $\Delta$. Merely out of preference, our
``Kripke-like'' model restricts the domain and codomain to be a
weakening ($\Gamma,\Delta$) of the original context ($\Gamma$).
}
\end{mycase}

\end{mydefinition}

So how does this model help us to define the application case of
evaluation? The result of evaluation (rather than
normalization) is a semantic value (rather than a syntactic value).
Thus, evaluating the function produces a semantic
function (a function in the metalanguage), which we can apply to the semantic value produced by evaluating
the argument (in this case the weakening $\Delta$ is merely the empty
context). Hence, we can define the application case of evaluation in
an structurally terminating way since it only needs to appeal to the
inductive hypotheses for the function and its argument. The inductive
hypothesis for the function produces a metalanguage function that we
can apply, rather than a syntactic $\lambda$ and a body for which we
would be missing an inductive hypothesis.

Given that evaluation must map syntactic expressions to semantic values,
what should it do when it encounters a variable? We can make
evaluation take an additional argument, called the
``semantic environment'', mapping variables to semantic values. More
specifically, the semantic environment maps all types (where each type
represents a variable) in some initial context $\Gamma$ to semantic
values in some terminal context $\Delta$. Because the environment
values are scoped by $\Delta$, evaluation works on open terms,
hence NbE can define strong normalization.

\begin{mydefinition}{Semantic Environments}{menv}
{
The model of environments $\menv$ is defined inductively on the structure
of the second argument ($\Gamma$). We refer to any member of the model
of environments as a ``semantic environment''.
}

\begin{mycase}[Empty context]
$$
\dmenv{\emp} \dfn \top
$$
The empty context is trivially inhabited in the environment model.
\end{mycase}

\begin{mycase}[Context extension]
$$
\dmenv{\Gamma, A} \dfn \dmenv{\Gamma} \cross \dtypm{A}
$$

The environment model of a context extension consists of two parts,
given as a pair type. The first part
is a semantic environment for the context being extended ($\Gamma$). The second part
is a semantic value in the terminal context ($\Delta$),
whose type is the type of the context extension ($A$).

\end{mycase}

\end{mydefinition}

\subsection{Normalization by Evaluation}

So far we have seen the model of values and environments, and the
intuition behind the model enabling a terminating definition of evaluation.
Now let's take a closer look at how exactly to define normalization in
terms of evaluation. What theorems 
\footnote{Because the ``definition'' of normalization contains an
intrinsic termination proof, we refer to normalization, evaluation, and
related ``definitions'' as \textit{theorems} and \textit{lemmas}.}
do we need, and how do we instantiate these theorems in the proof of
normalization?

\begin{mytheorem}{Normalization by Evaluation}{nbe}
{
\nbe : \nbeT
}
{
\refapp{eval} & \refthm{eval} & $\eval$ & $\evalT$ \\
\hline
\refapp{reify} & \refthm{reify} & $\reify$ & $\reifyT$ \\
\hline
\refapp{reflectc} & \refthm{reflectc} & $\reflectc$ & $\reflectcT$ \\
}

The high-level plan of NbE is to define
normalization as the composition of evaluation ($\eval$) of a syntactic expression to a
semantic value, and reification ($\reify$) back to a syntactic value.
Normalization takes a syntactic expression to a syntactic value,
while evaluation takes a syntactic expression \textit{and} a semantic
environment to a semantic value. So what should we use for the semantic
environment argument when defining normalization in terms of
evaluation? We can reflect any context ($\Gamma$) as a semantic
environment ($\reflectc$). Specifically, a context is reflected as the
identity semantic environment, mapping syntactic variables to
themselves, but as semantic values.

\begin{myproof}{}
\begin{align*}
e    &: \type{A} && \byass\\
\sigma &: \cmenv{\Gamma}{\Gamma} && \by{\reflectc~\Gamma}\\
v  &: \typm{A} && \by{\eval~e~\sigma}\\
v' &: \typv{A} && \by{\reify~v}
\end{align*}

The diagram of NbE in the introduction left out some details, as it
was only meant to convey the intuition behind NbE. However, we can
fill in the details to arrive at the alternative pictorial proof
below.

\begin{displaymath}
    \xymatrix{
          {(e : \type{A})} 
          \ar[dr]_{\nbe~e}
          \ar[r(0.77)]^*++{\labelstyle ~~~~~~~~~~~~~~ \eval~e~(\reflectc~\Gamma)}
        & {~~~~~~~(v : \typm{A})}
          \ar[d]^{\large{\reify~v}}
\\      & \typv{A} }
\end{displaymath}

\end{myproof}

\end{mytheorem}

\subsection{Hereditary Substitution by Canonical Evaluation}

How is the type of hereditary substitution different from that of
normalization? First, we are substituting into a \textit{value} rather
than normalizing an \textit{expression}. Second, hereditary
substitution also takes a \textit{syntactic} environment, a mapping of
variables to syntactic values, as an additional argument.
\footnote{
What we call a
``syntactic environment'' is normally called a ``substitution''.
Because we refer so much to the operation of hereditary substitution,
it is less ambiguous to refer to its ``substitution'' argument as a
``syntactic environment''.
}

\begin{mydefinition}{Syntactic Environments}{env}
{
Syntactic environments $\env$ are defined as a cartesian product, exactly like semantic
environments (\refdef{menv}, $\menv$), except they contain syntactic values
instead of semantic values. 
}
\end{mydefinition}

\begin{mytheorem}{Hereditary Substitution by Canonical Evaluation}{sbe}
{
\sbe : \sbeT
}
{
\refsec{ceval} & \refthm{cevalv} & $\cevalv$ & $\cevalvT$ \\
\hline
\refapp{reify} & \refthm{reify} & $\reify$ & $\reifyT$ \\
\hline
\refsec{reflecte} & \refthm{reflecte} & $\reflecte$ & $\reflecteT$ \\
}

Above are the theorems we need for SbE. In particular, notice that we
get to reuse $\reify$ from NbE.
The high-level plan of SbE is to define
hereditary substitution as the composition of
canonical evaluation ($\cevalv$) of a syntactic value to a
semantic value, and reification ($\reify$) back to a syntactic value.
What exactly is canonical evaluation? Recall that evaluation of
expressions turns syntactic expressions into semantic values, reducing
$\beta$-redexes and replacing variables with their definition in the
semantic environment ($\sigma$) along the way. On the other hand,
canonical evaluation takes a syntactic value and a semantic environment
to a semantic value. It will not come across $\beta$-redexes in the input
syntactic value, but replacing variables with semantic values (from
$\sigma$) may \textit{introduce} $\beta$-redexes that need to be
immediately reduced. Finally, the syntactic environment argument ($\sigma$) of
SbE is reflected ($\reflecte$) as a semantic environment, and is used
as the semantic environment argument of canonical evaluation.

\begin{myproof}{}
\begin{align*}
v    &: \typv{A} && \byass\\
\sigma   &: \env && \byass\\
\sigma'  &: \menv && \by{\reflecte~\sigma}\\
v'   &: \dtypm{A} && \by{\cevalv~v~\sigma'}\\
v''  &: \dtypv{A} && \by{\reify~A~v'}
\end{align*}

Once again, we can add detail to the commutative diagram of SbE in the
introduction to arrive at the alternative pictorial proof below.

\begin{displaymath}
    \xymatrix{
          {(v : \typv{A}) ~ (\sigma : \env)} 
          \ar[dr]_{\sbe~v~\sigma}
          \ar[r(0.80)]^*++{\labelstyle ~~~~~~~~~~~~~~~~~~~~ \cevalv~v~(\reflecte~\sigma)}
        & {~~~~~~~(v' : \dtypm{A})}
          \ar[d]^{\large{\reify~v'}}
\\      & \dtypv{A} }
\end{displaymath}

\end{myproof}

\end{mytheorem}

\subsection{NbE versus SbE}

In the world of expressions,
evaluation takes an additional argument (the semantic environment) compared
to normalization, which only takes the expression to reduce. But, in
the world of values hereditary substitution and canonical evaluation
both take a value, an environment, and produce a value. The only
difference is that canonical evaluation takes a semantic environment and
produces a semantic value. 
In other words, canonical evaluation \textit{is}
a model-theoretic hereditary substitution, compared to the typical
proof-theoretic hereditary substitution.
What a beautiful coincidence!

A consequence of this is that normalization must invent a semantic
environment to pass to evaluation, because it does not already
have a syntactic environment argument to reflect. Because normalization does not
change the value of free variables, the identity semantic environment
can be used by reflecting the context ($\reflectc$). In contrast, hereditary substitution already has
a syntactic environment (that is used to look up the value of any free
variables), so canonical evaluation takes the 
reflection ($\reflecte$) of the syntactic environment as its semantic
environment argument. More generally, an important difference between
normalization and hereditary substitution is that the former preserves
the type ($A$) and context ($\Gamma$) of its input, while the latter
only preserves its type (the context changes to $\Delta$).

Although there is a more direct correspondence between SbE and canonical
evaluation (than there is between NbE and evaluation), there is
nothing preventing us from defining a function on expressions that
normalizes $\beta$-redexes, and simultaneously performs hereditary
substitutions from an environment mapping variables to expressions.
This normalization plus hereditary substitution function ($\nsbe$) would take an
extra syntactic expression environment argument, creating a
correspondence with evaluation that is just as direct as the one that
SbE enjoys.

$$
\nsbe : \type{A} \marr \enve \marr \dtypv{A}
$$


\section{Canonical Evaluation}
\label{sec:ceval}

Canonical evaluation ($\cevalv$) is the primary definition in SbE, taking a
syntactic value and a semantic environment to a semantic value. It is
analogous to evaluation ($\eval$) in NbE. In fact canonical evaluation
is defined exactly the same way that evaluation is, except by case
analysis over values instead of expressions!

Because the grammar of values is mutually defined with neutrals,
canonical evaluation of values ($\cevalv$) is mutually defined with canonical
evaluation of neutrals ($\cevaln$). Recall that values consist of axioms and
inference rules for all constructors, plus an inference rule for
injecting neutrals into values. A neutral is a variable, or 
sequence of eliminations (i.e. applications or primitive recursions)
that begins with the elimination of a variable.

Expressions and values are quite different, as the former
may contain $\beta$-redexes. However, if you compare
canonical evaluation (\refthm{cevalv} \& \reflem{cevaln}) with
evaluation (\refthm{eval} in \refapp{eval}) you will notice that they are identical,
modulo the former being defined over a split grammar. Why is that?
An expression may already be a syntactic $\beta$-redex, while a
syntactic value will never be a syntactic $\beta$-redex. But, both an
expression and a value may become a semantic $\beta$-redex (a
$\beta$-redex of the metalanguage) after replacing syntactic variables
with values from the semantic environment. 

Essentially, evaluation and canonical evaluation are similar because
they operate on variables the same way, replacing them with semantic
values from the semantic environment. In contrast,
normalization leaves variables unchanged, while hereditary
substitution replaces variables with syntactic values from the
syntactic environment. 

\begin{mytheorem}{Canonical Evaluation of Values}{cevalv}
{
\cevalv : \cevalvT
}
{
\refsec{ceval} & \reflem{cevaln} & $\cevaln$ & $\cevalnT$ \\
\hline
\refapp{reflectc} & \reflem{monos} & $\monos$ & $\monosT$ \\
}

Canonical evaluation ($\cevalv$) is a type-preserving
translation. It takes a syntactic value in some
initial context ($\typv{A}$) and a semantic environment in some
terminal context ($\menv$), and produces a
semantic value in the terminal context ($\dtypm{A}$). The semantic environment
has a semantic value for every type in the initial context, each of which
must be scoped in the terminal context. 

\begin{myproof}
{
By induction on the value $\typv{A}$.
}


\begin{mycase}[Zero]
{
The zero case is immediate.
}
\begin{align*}
n  &: \dtypv{\nat} && \by{\zero}\\
n  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Successor]
{
The successor case is a congruence.
}
\begin{align*}
n   &: \typv{\nat} && \byass\\
\sigma  &: \menv && \byass\\
n'  &: \dtypm{\nat} && \ih{\cevalv~n~\sigma}\\
n'  &: \dtypv{\nat} && \bydef\\
m   &: \dtypv{\nat} && \by{\suc~n'}\\
m  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Function]
{
When canonically evaluating a function (a $\lam$ term),
the return type is a model function (a metalanguage function).
We get two standard parameters from the theorem ($b$ and $\sigma$), but
because we return a metalanguage function we also get two additional
parameters from its domain ($\Xi$ and $a$). The $\Xi$
parameter is a context to weaken the result with, and the $a$
parameter is a semantic value that has been weakened by $\Xi$. Review the
function case of $\typm{A \arr B}$ in \refdef{mval} to see where the
two additional parameters come from.

We would like to produce a result by canonically evaluating the
$\lambda$-body $b$, using the semantic environment $\sigma$ extended
by the extra argument $a$ that we received from the model. However,
all of the semantic values in the semantic environment are scoped
under $\Delta$, while semantic value $a$ is scoped under $\Delta,\Xi$.
Thus, we must use the $\monos$ lemma from \refapp{reflectc} to
transform $\sigma$. The
reader can recognize $\monos$ as a form of weakening (we are weakening
$\Delta$ by $\Xi$ above) lifted to semantic environments.

}
\begin{align*}
b   &: \gatypv{B} && \byass\\
\sigma  &: \menv && \byass\\
\Xi& && \byass\\
a   &: \el{\Delta, \Xi \vdash A} && \byass\\
\sigma'  &: \gmenv{\Delta, \Xi} && \by{\monos~\Xi~\sigma}\\
b'  &: \dtypm{B} && \ih{\cevalv~b~(\sigma', a)}\\
\end{align*}
\end{mycase}

\begin{mycase}[Neutral]
{
Canonical evaluation of neutrals is delegated to a mutually defined
theorem ($\cevaln$).
}
\begin{align*}
a   &: \typn{A} && \byass\\
\sigma  &: \menv && \byass\\
a'  &: \dtypm{A} && \ih{\cevaln~a~\sigma}
\end{align*}
\end{mycase}


\end{myproof}

\end{mytheorem}

\begin{mylemma}{Canonical Evaluation of Neutrals}{cevaln}
{ \cevaln : \cevalnT }
{
\refsec{ceval} & \refthm{cevalv} & $\cevalv$ & $\cevalvT$ \\
\hline
\refapp{eval} & \reflem{mrec} & $\mrec$ & $\mrecT$ \\
}

Canonical evaluation of neutrals ($\cevaln$) handles the canonical
evaluation of variables and eliminations, and is used as a lemma in
the mutually defined canonical evaluation of values ($\cevalv$).

\begin{myproof}
{
By induction on the neutral $\typn{A}$.
}

\begin{mycase}[Variable]
{
Canonically evaluate a variable by looking up its corresponding semantic
value in the semantic environment.
}
\begin{align*}
i   &: \typr{A} && \byass\\
\sigma  &: \menv && \byass\\
a  &: \dtypm{A} && \by{\textit{lookup} ~ \sigma[i]}
\end{align*}
\end{mycase}

\begin{mycase}[Application]
{
The whole point of the value model
(\refdef{mval}) is to make this case easy to define. Evaluating the
applied function (the first inductive hypothesis) results in a metalanguage function, which we can
apply to an empty context extension ($\emp$) and the result of
evaluating the argument of the function application (the second
inductive hypothesis).
}
\begin{align*}
f   &: \typn{A \arr B} && \byass\\
a   &: \typv{A} && \byass\\
\sigma  &: \menv && \byass\\
f'  &: \dtypm{A \arr B} && \ih{\cevaln~f~\sigma}\\
f'  &: \all{\Delta} \gdtypm{A} \marr \gdtypm{B} && \bydef\\
a'  &: \dtypm{A} && \ih{\cevalv~a~\sigma}\\
b   &: \dtypm{B} && \by{f'~\emp~a'}
\end{align*}
\end{mycase}

\begin{mycase}[Primitive recursion]
{
When canonically evaluating a neutral primitive
recursion ($\rec$), we can get inductive hypotheses for all the
arguments to the primitive recursion, but we must perform a semantic version of
primitive recursion using a lemma ($\mrec$). The lemma
$\mrec$ was developed for evaluation in NbE, and is given in
\refapp{eval} as \reflem{mrec}.
}
\begin{align*}
c_z  &: \typv{C} && \byass\\
c_s  &: \typv{C \arr C} && \byass\\
n    &: \typn{\nat} && \byass\\
\sigma  &: \menv && \byass\\
c_z' &: \dtypm{C} && \ih{\cevalv~c_z~\sigma}\\
c_s' &: \dtypm{C \arr C} && \ih{\cevalv~c_s~\sigma}\\
n'   &: \dtypm{\nat} && \ih{\cevaln~n~\sigma}\\
c    &: \dtypm{C} && \by{\el{\rec}~c_z'~c_s'~n'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mylemma}


\section{Environment Reflection}
\label{sec:reflecte}

Environment reflection takes a context ($\Delta$) and a syntactic
environment ($\env$), and produces a semantic environment ($\menv$).
Recall that a syntactic environment (\refdef{env} in \refsec{overview})
is a tuple of syntactic values, all scoped under the same context.
In contrast, a semantic environment (\refdef{menv} in \refsec{overview})
is a tuple of semantic values, all scoped under the same context.

\begin{mytheorem}{Environment Reflection}{reflecte}
{ \reflecte : \reflecteT }
{
\refsec{ceval} & \refthm{cevalv} & $\cevalv$ & $\cevalvT$ \\
\hline
\refapp{reflectc} & \refthm{reflectc} & $\reflectc$ & $\reflectcT$ \\
}

Environment reflection is a context-preserving mapping from
syntactic environments to semantic environments. So how do we
translate a single syntactic value ($\dtypv{A}$) in the syntactic
environment ($\env$) to a semantic value ($\dtypm{A}$) in the same
context? We canonically evaluate it, but what should the semantic
environment for canonical evaluation be? Because we do not want the
context to change in the result of canonical evaluation, we can pass
it the identity semantic environment ($\dmenv{\Delta}$) via
context reflection (\refthm{reflectc} in \refapp{reflectc}).

\begin{myproof}
{
By induction on the environment $\env$.
}

\begin{mycase}[Empty environment]
{
The empty environment case is trivial.
}
\begin{align*}
\Delta& && \byass\\
u &: \top && \byass\\
u &: \menv && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Environment extension]
{
To reflect a syntactic environment ($\sigma$) extended by a syntactic
value ($x$), we must produce a semantic environment extended by a
semantic value. The induction hypothesis gives us the semantic
environment.

To get the semantic value we must canonically evaluate
the syntactic value argument ($x$).
The second parameter of canonical evaluation is an environment, which
determines the context that the resulting semantic value is scoped
under. Because our syntactic value $x$ already has the correct scope
($\Delta$), we can use context reflection (of $\Delta$) as the
semantic environment argument for canonical evaluation.
}
\begin{align*}
\Delta& && \byass\\
\sigma &: \env && \byass\\
x    &: \dtypv{A} && \byass\\
\sigma'  &: \menv && \ih{\reflecte~\Delta~\sigma}\\
\delta  &: \dmenv{\Delta} && \by{\reflectc~\Delta}\\
x'   &: \dtypm{A} && \by{\cevalv~x~\delta}\\
\sigma'' &: \dmenv{\Gamma, A} && \by{\sigma', x'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mytheorem}

\subsection{No Circularity}

If you look back at the definition of SbE (\refthm{sbe} in
\refsec{overview}), it might now seem circular. SbE is defined by
canonically evaluating a syntactic value, but canonical evaluation
also takes a semantic environment. So before canonically evaluating
the syntactic value, we must reflect the syntactic environment to a
semantic environment. However, environment reflection (\refthm{reflecte}) is once again
defined by canonical evaluation, which needs a semantic environment
for each syntactic value in the reflected syntactic environment.

Fortunately, the circularity is broken because we can always produce
an identity semantic environment (mapping variables to themselves as
semantic values) out of thin air using context reflection
(\refthm{reflectc} in \refapp{reflectc}).

\section{Related \& Future Work}
\label{sec:related}

Below we compare and contrast model-theoretic hereditary substitution
(SbE) with conventional proof-theoretic hereditary substitution. In
particular, we point out that the model-theoretic version scales to
calculi with inductive types. We also discuss some future work, namely
scaling SbE to calculi with features like delimited control, and
proving correctness of SbE.

\subsection{Proof-Theoretic Hereditary Substitution}

Techniques similar to hereditary substitution originated in the world
of proof theory. For example, Prawitz~\cite{prawitz} proved that
normalization of natural deduction terminates via a lexicographic
ordering on proposition (types) and proofs (terms). This syntactic
proof is similar to a definition of hereditary substitution.
Joachimski et al.~\cite{permutative} showed that normalization of
various expression-based $\lambda$-calculi (even G{\"o}del's System T)
terminates using a syntactic argument also resembling hereditary
substitution. Watkins~\cite{watkins} explicitly defined
hereditary substitution by proving termination of a semantics for a concurrent
logical framework.

There has also been work on formalizing the syntactic termination
argument of hereditary substitution in type theory. This is done by defining
hereditary substitution as a total function with an implicit
termination proof that relies on the lexicographic termination
argument on types and terms. For example, Keller and Altenkirch~\cite{keller}
define hereditary substitution this way within Agda for the Simply
Typed Lambda Calculus (STLC). Similarly, Abel~\cite{abelhsub} defines
simultaneous hereditary substitution for STLC in Agda. However,
extending formal, syntactic, and implicit termination arguments of
hereditary substitution to richer calculi has been more difficult. For
example, Eades~\cite{eadesreach} discusses the difficulties with
extending proof-theoretic hereditary substitution to richer calculi.
In particular, the termination argument becomes troublesome in
calculi with inductive types. Eades~\cite{eadessystemf} has overcome
the problems for predicative System F and STLC with sum types.
However, formal and implicit termination arguments of hereditary
substitution for calculi with recursive sum types, such as natural
numbers (G{\"o}del's System T) or parametric lists, remain to be discovered.

\subsection{Model-Theoretic Hereditary Substitution}

SbE is a model-theoretic definition of hereditary substitution. It is
derived from NbE by adapting evaluation to work on canonical terms,
rather than expressions. Because SbE reuses so much from NbE, it also enjoys
many of its benefits. For example, NbE can be used to define
normalization of STLC within type theory as a function with an
implicit termination proof. Coquand~\cite{coquandnbe} first formalized NbE for
STLC in Alf~\cite{alf}. It is also easy to formalize NbE for STLC in Agda,
as demonstrated by Morrison~\cite{morrison} and Ilik~\cite{ilik}.

Significantly, type theoretic formalizations of NbE have been easy to
extend to more complex calculi, such as calculi with inductive types.
Ilik~\cite{ilik} shows how to formalize NbE in Agda for a $\lambda$-calculus
with sums, polymorphic lists, and even delimited control. 

Because SbE is an adaption of NbE to canonical terms, it is easy to
adapt formalizations of NbE for complex calculi to SbE. For example,
our accompanying code implements SbE for a calculus with polymorphic
lists and folds over them. It should be just as easy to adapt Ilik's NbE
formalization of delimited control to SbE.

\subsection{Correctness}

Because NbE allows you to write normalization as a function within
type theory, you may be content with this normalization
function acting as both the specification and the implementation of
the semantics for your calculus. Otherwise, you may wish to prove that
normalization is both sound and complete with respect to a
relationally specified equivalence relation on expressions.

Similarly, you may accept normalization defined in terms of SbE
($\nbs$ in \refapp{nbs}) as the specification and implementation of a semantics
for expressions. If you do not accept this, then you may wish to prove
the following correctness theorem.

$$
\nbs~e_1 \equiv \nbs~e_2 ~\leftrightarrow~ e_1 \approx_\beta e_2
$$

The theorem requires normalization by hereditary substitution (\nbs)
to be sound (the ``if'' direction) and complete
(the ``only if'' direction) with respect to a relational specified
$\beta$-equivalence relation. Note that because we are using De Bruijn
variables, the left-hand side only requires strict equality between
the values produced from normalizing the input expressions. 

We have not yet proven the theorem above for SbE, but because so much
of SbE is derived from NbE, we expect proving this theorem to
borrow proof machinery from the NbE world. We expect the completeness
direction to be proven using a logical relation, similar to the proof
that Abel~\cite{abelhabil} gives for NbE completeness.
We expect the soundness direction of SbE to be provable directly, like
the soundness direction of NbE also mentioned by Abel~\cite{abelhabil}.
We expect the soundness proof to require several
``commutation lemmas'', as described by Keller and
Altenkirch~\cite{keller}, and as used in their correctness proof of syntactic hereditary substitution. 
The commutation lemmas ensure that
hereditary substitution into values commutes with ordinary substitution
into expressions.

\section{Conclusion}
\label{sec:conclusion}

Normalization by Evaluation (NbE) makes it possible to formalize an
intrinsic termination argument of the normalization of expressions for
many $\lambda$-calculi (e.g. calculi with polymorphic lists, sums,
continuations, etc). 

If you adapt the evaluation part of NbE from expressions to canonical
terms, you get a function with an intrinsic termination proof that
maps a syntactic value and a semantic environment to a semantic value.
We call this function canonical evaluation. By beautiful coincidence,
canonical evaluation is \textit{semantic} hereditary substitution. In
other words, it is the
lifting of \textit{syntactic} hereditary substitution to semantic values of a
Kripke model.

After noticing that canonical evaluation is semantic hereditary
substitution, we showed how to define syntactic hereditary
substitution by reflecting its environment argument and reifying the
result of canonical evaluation. We call this technique Hereditary
Substitution by Canonical Evaluation (SbE). When defining SbE, we get
to reuse many definitions, theorems, and lemmas from NbE, such as the
model and reification. Finally, hereditary substitution for complex
$\lambda$-calculi can be formalized within dependently typed languages
as a function with an intrinsic termination proof!

\subsubsection*{Acknowledgments.}
We would like to thank Andrew Cave for helping us understand subtle
issues related to context weakening when formalizing termination
proofs via realizability predicates. We would also
like to thank Darin Morrison for originally introducing us to the connection
between NbE and a Kripke model for intuitionistic logic. Finally, we
would like to thank Clarissa Littler and Ki Yung Ahn for giving
valuable feedback on drafts of this paper.
This work was supported by NSF/CISE/CCF grant \#1320934.



\bibliographystyle{splncs03}
\bibliography{sbe}

\clearpage

\section*{\appendixname}
\appendix

\section{Evaluation}
\label{sec:eval}

Evaluation of expressions in NbE is like canonical evaluation of
values in SbE. The proof of evaluation below does not describe how
each case works, because it is essentially the same as
canonical evaluation (\refthm{cevalv} and \reflem{cevaln} in
\refsec{ceval}). We invite the reader to compare the proofs of
evaluation and canonical evaluation to verify their similarity.
Whereas canonical evaluation is defined separately for neutrals,
evaluation is a single definition for all syntactic forms.

\begin{mytheorem}{Evaluation}{eval}
{ \eval : \evalT }
{
\refapp{reflectc} & \reflem{monos} & $\monos$ & $\monosT$ \\
\hline
\refapp{eval} & \reflem{mrec} & $\mrec$ & $\mrecT$ \\
}

Evaluation ($\eval$) is a type-preserving
translation. It takes a syntactic expression in some
initial context ($\type{A}$) and a semantic environment in some
terminal context ($\menv$), and produces a
semantic value in the terminal context ($\dtypm{A}$). The semantic environment
has a semantic value for every type in the initial context, each of which
must be scoped in the terminal context. 

\begin{myproof}
{
By induction on the expression $\type{A}$.
}

\begin{mycase}[Zero]{}
\begin{align*}
n  &: \dtype{\nat} && \by{\zero}\\
n  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Successor]{}
\begin{align*}
n   &: \type{\nat} && \byass\\
\sigma  &: \menv && \byass\\
n'  &: \dtypm{\nat} && \ih{\eval~n~\sigma}\\
n'  &: \dtype{\nat} && \bydef\\
m   &: \dtype{\nat} && \by{\suc~n'}\\
m  &: \dtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Function]{}
\begin{align*}
b   &: \gatype{B} && \byass\\
\sigma  &: \menv && \byass\\
\Xi& && \byass\\
a   &: \el{\Delta, \Xi \vdash A} && \byass\\
\sigma'  &: \gmenv{\Delta, \Xi} && \by{\monos~\Xi~\sigma}\\
b'  &: \dtypm{B} && \ih{\eval~b~(\sigma', a)}\\
\end{align*}
\end{mycase}

\begin{mycase}[Variable]{}
\begin{align*}
i   &: \typr{A} && \byass\\
\sigma  &: \menv && \byass\\
a  &: \dtypm{A} && \by{\textit{lookup} ~ \sigma[i]}
\end{align*}
\end{mycase}

\begin{mycase}[Application]{}
\begin{align*}
f   &: \type{A \arr B} && \byass\\
a   &: \type{A} && \byass\\
\sigma  &: \menv && \byass\\
f'  &: \dtypm{A \arr B} && \ih{\eval~f~\sigma}\\
f'  &: \all{\Delta} \gdtypm{A} \marr \gdtypm{B} && \bydef\\
a'  &: \dtypm{A} && \ih{\eval~a~\sigma}\\
b   &: \dtypm{B} && \by{f'~\emp~a'}
\end{align*}
\end{mycase}

\begin{mycase}[Primitive recursion]{}
\begin{align*}
c_z  &: \type{C} && \byass\\
c_s  &: \type{C \arr C} && \byass\\
n    &: \type{\nat} && \byass\\
\sigma  &: \menv && \byass\\
c_z' &: \dtypm{C} && \ih{\eval~c_z~\sigma}\\
c_s' &: \dtypm{C \arr C} && \ih{\eval~c_s~\sigma}\\
n'   &: \dtypm{\nat} && \ih{\eval~n~\sigma}\\
c    &: \dtypm{C} && \by{\el{\rec}~c_z'~c_s'~n'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mytheorem}

\begin{mylemma}{Semantic Primitive Recursion}{mrec}
{
\mrec : \mrecT
}
{
\refapp{reify} & \refthm{reify} & $\reify$ & $\reifyT$ \\
\hline
\refapp{reify} & \reflem{reflectn} & $\reflectn$ & $\reflectnT$ \\
}

Semantic primitive recursion ($\mrec$) is the lifting of the syntax of
primitive recursion ($\rec$) to the model (the semantic domain). It
takes a semantic value for zero branch, a semantic value for the
successor case, and a semantic value for the natural number to recurse
over.

Because the model of natural numbers is just a natural number value,
the model of primitive recursion works basically the same way that
normalization of primitive recursion would work in the theory. The
main difference is that the arguments and return type are really
elements of the model. In particular, the successor branch for the
primitive recursion is a model function that we may simply apply to
other model values (i.e. the induction hypothesis).

\begin{myproof}
{
By induction on the semantic natural number value $\typm{\nat}$.
Definitionally, this reduces to induction on the syntactic natural number
value $\typv{\nat}$.
}

\begin{mycase}[Zero]
{
The zero case is immediate.
}
\begin{align*}
c_z  &: \typm{C} && \byass
\end{align*}
\end{mycase}

\begin{mycase}[Successor]
{
In the successor case we first get the inductive hypothesis for the
predecessor. Because the successor branch argument is a semantic value
of function type, it is a metalanguage function. Thus, we compute the
result by applying the successor branch to the empty context
(weakening by nothing), and the inductive hypothesis.
}
\begin{align*}
c_z  &: \typm{C} && \byass\\
c_s  &: \typm{C \arr C} && \byass\\
n    &: \typv{\nat} && \byass\\
n    &: \typm{\nat} && \bydef\\
c    &: \typm{C} && \ih{\mrec~c_z~c_s~n}\\
c_s  &: \all{\Delta} \gdtypm{C} \marr \gdtypm{C} && \bydef\\
c'   &: \typm{C} && \by{c_s~\emp~c}
\end{align*}
\end{mycase}

\begin{mycase}[Neutral]
{
If the value that we are trying to recurse over is neutral, then we
reflect a syntactic primitive recursion stuck on the neutral input,
while reifying both branch arguments.
}
\begin{align*}
c_z  &: \typm{C} && \byass\\
c_s  &: \typm{C \arr C} && \byass\\
n    &: \typn{\nat} && \byass\\
c_z' &: \typv{C} && \by{\fun{reify}~c_z}\\
c_s' &: \typv{C \arr C} && \by{\fun{reify}~c_s}\\
c'   &: \typn{C} && \by{\fun{rec}~c_z'~c_s'~n}\\
c''  &: \typm{C} && \by{\fun{reflect}~c'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mylemma}

\section{Reification}
\label{sec:reify}

Reification (\refthm{reify}) is the process of turning a semantic
value into a syntactic value. It is defined mutually with the
reflection (\reflem{reflectn}) of neutrals to semantic values.

\begin{mytheorem}{Reification}{reify}
{
\reify : \reifyT
}
{
\refapp{reify} & \reflem{reflectn} & $\reflectn$ & $\reflectnT$ \\
}

Reification maps any semantic value ($\typm{A}$) to a syntactic 
value ($\typv{A}$). It is mutually defined with the reflection of
syntactic neutrals to semantic values ($\reflectn$), making it
possible to reify functions.

\begin{myproof}
{
By induction on the type $A$.
}

\begin{mycase}[Natural numbers]
{
Semantic natural numbers values are also syntactic values,
so their reification is immediate.
}
\begin{align*}
n  &: \typm{\nat} && \byass\\
n  &: \typv{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Functions]
{
When reifying a function (of type $A \arr B$) we get a metalanguage
function as a parameter. The function parameters are a context to weaken by
and a weakened semantic value (of type $A$).

We would like to call the function, but we cannot a produce a semantic
value of type $\typm{A}$ out of thin air. What if we make the
weakening parameter of the metalanguage function be the singleton
context $\emp, A$? Now we can call the function by making the (now
weakened) parameter $\gatypm{A}$ be a variable! However, the variable
must be a semantic value. Luckily, the mutually defined lemma
$\reflectn$ can translate any syntactic neutral term (including
variables) to a semantic value.

Finally, we reify the result of the metalanguage function and
wrap it in a $\lambda$. Note that in this appeal to the inductive
hypothesis the type gets smaller ($B$ is smaller $A \arr B$). When
reflecting the variable after weakening, the type also gets smaller
($B$ is smaller $A \arr B$).
}
\begin{align*}
f &: \typm{A \arr B} && \byass\\
f &: \all{\Delta} \gdtypm{A} \marr \gdtypm{B} && \bydef\\
a &: \gatypm{A} && \ih{\reflect~(\con{var here})}\\
b &: \gatypm{B} && \by{f~(\emp, A)~a}\\
b' &: \gatypv{B} && \ih{\fun{reify}~b}\\
f' &: \typv{A \arr B} && \by{\lam b'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mytheorem}

\begin{mylemma}{Neutral Reflection}{reflectn}
{
\reflectn : \reflectnT
}
{
\refapp{reify} & \refthm{reify} & $\reify$ & $\reifyT$ \\
}

The reflection of neutrals maps any syntactic neutral ($\typn{A}$) to
a semantic value ($\typm{A}$). Note that we can only reflect syntactic
neutrals, not syntactic values! If we could reflect syntactic values,
then this would be like canonical evaluation of values without the
semantic environment argument. However, the semantic environment
allows the semantic values to be collected when canonically evaluating
underneath a function body.

\begin{myproof}
{
By induction on the type $A$.
}

\begin{mycase}[Natural numbers]
{The natural number case is immediate.}
\begin{align*}
n  &: \typn{\nat} && \byass\\
n' &: \typv{\nat} && \by{\con{neut}~n}\\
n' &: \typm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Functions]
{
To reflect a neutral function, we get a syntactic neutral function $f$ as
a standard argument. Because we are producing a metalanguage function,
we also get $\Delta$ and $a$ as additional arguments. Reifying $a$
changes it from a semantic value to a syntactic value. Now, we can
appeal to the inductive hypothesis to reflect the \textit{application}
of a weakened version of $f$ to the reified $a$. The reason why
reflection of the function case is okay for neutrals, but not values,
is because application of a syntactic neutral function to a syntactic
value argument produces a syntactic neutral result. Finally, note that
the appeal to the inductive hypothesis is decreasing on the size of
the type (where $B$ is smaller than $A \arr B$), not the size of the term.
}
\begin{align*}
f &: \typn{A \arr B} && \byass\\
\Delta& && \byass\\
a  &: \gdtypm{A} && \byass\\
a' &: \gdtypv{A} && \ih{\fun{reify}~a}\\
f' &: \gdtypn{A \arr B} && \bywkn\\
b  &: \gdtypm{B} && \ih{\reflect~(f' \cdot a')}
\end{align*}
\end{mycase}

\end{myproof}

\end{mylemma}


\section{Context Reflection}
\label{sec:reflectc}

Context reflection (\refthm{reflectc}) gives a semantic meaning to a
context by translating it to a semantic environment.
Specifically, context reflection produces the identity
semantic environment, mapping variables to themselves as semantic values.
Context reflection makes use of environment monotonicity (\reflem{monos}),
and environment monotonicity makes use of
value monotonicity (\reflem{mono}). Both monotonicity lemmas are
basically a version of weakening lifted from syntax to semantics, for
environments and values respectively.

\begin{mytheorem}{Context Reflection}{reflectc}
{ \reflectc : \reflectcT }
{
\refapp{reify} & \reflem{reflectn} & $\reflectn$ & $\reflectnT$ \\
\hline
\refapp{reflectc} & \reflem{monos} & $\monos$ & $\monosT$ \\
}

Context reflection takes a new context ($\Gamma$), and produces a semantic
environment ($\gmenv{\Gamma}$).
At a high level, context reflection produces the semantic identity environment
by reflecting each variable in the context.

\begin{myproof}
{
By induction on the context $\Gamma$.
}

\begin{mycase}[Empty context]
{
The empty context case is trivial.
}
\begin{align*}
u &: \top && \bytri\\
u &: \cmenv{\emp}{\emp} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Context extension]
{
To produce a semantic identity environment for a context extension,
we must extend the inductive hypothesis with the reflection of the
variable representing the type ($A$) extending the context. However,
the scope ($\Gamma,A$) of the variable includes the type of the
context extension ($A$). Thus, the semantic environment produced by
the inductive hypothesis must first be weakened, using environment
monotonicity ($\monos$), before it is extended with the reflected
variable.
}
\begin{align*}
\Gamma& && \byass\\
A& && \byass\\
\sigma  &: \cmenv{\Gamma}{\Gamma} && \ih{\reflectc~\Gamma}\\
\sigma' &: \cmenv{\Gamma}{\Gamma, A} && \by{\monos~(\emp, A)~\sigma}\\
x    &: \gatypm{A} && \by{\reflect~(\var~\here)}\\
\sigma'' &: \cmenv{\Gamma, A}{\Gamma, A} && \by{\sigma', x}
\end{align*}
\end{mycase}

\end{myproof}

\end{mytheorem}

\begin{mylemma}{Environment Monotonicity}{monos}
{ \monos : \monosT }
{
\refapp{reflectc} & \reflem{mono} & $\mono$ & $\monoT$ \\
}

Environment monotonicity takes a context ($\Delta$), and a semantic
environment scoped under some existing context ($\Xi$), and returns a
semantic environment scoped under the weakening of the existing
context ($\Delta,\Xi$).

Because a semantic environment is basically a tuple of semantic
values, environment monotonicity is defined by mapping value
monotonicity ($\mono$) across the tuple.

\begin{myproof}
{
By induction on the context $\Gamma$.
}

\begin{mycase}[Empty context]
{
The empty context case is trivial.
}
\begin{align*}
\Delta& && \byass\\
u &: \top && \byass\\
u &: \cmenv{\emp}{\Xi, \Delta} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Context extension]
{
To weaken the context extension of a semantic environment, extend the
inductive hypothesis with the weakening of the semantic value
extending the context by using $\mono$.
}
\begin{align*}
\Delta& && \byass\\
\sigma &: \gmenv{\Xi} && \byass\\
x    &: \xtypm{A} && \byass\\
\sigma'  &: \gmenv{\Xi, \Delta} && \ih{\monos~\Delta~\sigma}\\
x'   &: \xdtypm{A} && \by{\mono~\Delta~x}\\
\sigma'' &: \cmenv{\Gamma, A}{\Xi, \Delta} && \by{\sigma', x'}
\end{align*}
\end{mycase}

\end{myproof}

\end{mylemma}

\begin{mylemma}{Value Monotonicity}{mono}
{ \mono : \monoT }
{}

Value monotonicity takes a new context ($\Delta$), and a semantic
value scoped under some existing context ($\Gamma$), and returns a
semantic value scoped under the weakening of the existing context
($\Gamma,\Delta$).

\begin{myproof}
{
By case analysis of the type $A$.
}

\begin{mycase}[Natural numbers]
{
Because semantic natural numbers are syntactic natural numbers, the
natural number case can be defined via syntactic weakening.
}
\begin{align*}
\Delta& && \byass\\
n  &: \typm{\nat} && \byass\\
n  &: \typv{\nat} && \bydef\\
n' &: \gdtypv{\nat} && \bywkn\\
n' &: \gdtypm{\nat} && \bydef
\end{align*}
\end{mycase}

\begin{mycase}[Functions]
{
In the function case, we get the context $\Delta$ and the semantic
function $f$ as standard arguments. Additionally, we get a context
$\Xi$ and an argument $a$ as arguments because we are returning a
semantic function. We compute the required result by
applying the semantic function $f$ to the weakening ($\Delta,\Xi$) and
the semantic argument $a$. However, $a$ and the result must be
suitably altered using syntactic associativity of context
concatenation.
}
\begin{align*}
\Delta& && \byass\\
f  &: \typm{A \arr B} && \byass\\
\Xi& && \byass\\
a  &: \el{(\Gamma, \Delta), \Xi \vdash A} && \byass\\
a'  &: \el{\Gamma, (\Delta, \Xi) \vdash A} && \by{associativity}\\
f  &: \all{\Phi} \gftypm{A} \marr \gftypm{B} && \bydef\\
b  &: \el{\Gamma, (\Delta, \Xi) \vdash B} && \by{f~(\Delta,\Xi)~a'}\\
b'  &: \el{(\Gamma, \Delta), \Xi \vdash B} && \by{associativity}
\end{align*}
\end{mycase}

\end{myproof}

\end{mylemma}

\section{Normalization by Hereditary Substitution}
\label{sec:nbs}

Normalization by hereditary substitution (\refthm{nbs}) defines
normalization in terms of hereditary substitution in the function
application and primitive recursion cases. Application by
hereditary substitution (\reflem{abs}) is used in the application case
of normalization, and primitive recursion by hereditary substitution
(\reflem{rbs}) is used in the primitive recursion case
of normalization. Primitive recursion by hereditary substitution also
uses application by hereditary substitution in its successor case.

\begin{mytheorem}{Normalization by Hereditary Substitution}{nbs}
{
\nbs : \nbsT
}
{
\refapp{nbs} & \reflem{abs} & $\abs$ & $\absT$ \\
\hline
\refapp{nbs} & \reflem{rbs} & $\rbs$ & $\rbsT$ \\
}

Normalization by hereditary substitution takes a syntactic expression
of some context ($\Gamma$) and some type ($A$), and returns a
syntactic value of the same context and type. 

\begin{myproof}
{
By induction on the expression $\type{A}$.
}
\begin{align*}
&\nbs ~ \zero &&\dfun&& \zero\\
&\nbs ~ (\suc~n) &&\dfun&& \suc ~ (\nbs~n)\\
&\nbs ~ (\lam b) &&\dfun&& \lam (\nbs~b)\\
&\nbs ~ (\var~i) &&\dfun&& \neut ~ (\var~i)\\
&\nbs ~ (f~\app~a) &&\dfun&& \abs ~ (\nbs~f) ~ (\nbs~a)\\
&\nbs ~ (\rec~c_z~c_s~n) &&\dfun&& \rbs~(\nbs~c_z)~(\nbs~c_s)~(\nbs~n)
\end{align*}

All cases except for the eliminations translate expressions to values
immediately or via congruences. The application and primitive
recursion cases are handled by lemmas that work on values ($\abs$ and $\rbs$ respectively).

\end{myproof}

\end{mytheorem}

\begin{mylemma}{Application by Hereditary Substitution}{abs}
{
\abs : \absT
}
{
\refsec{overview} & \refthm{sbe} & $\sbe$ & $\sbeT$ \\
}

Application by Hereditary Substitution takes a syntactic function value
(of type $A \arr B$) and a syntactic value for the domain of the function
(of type $A$), and returns a syntactic value for the codomain of the
function (of type $B$).

\begin{myproof}
{
By induction on the function value $\typv{A \arr B}$.
}
\begin{align*}
&\abs ~ (\lam b) ~ a &&\dfun&& \sbe~b~(\idenv, a)\\
&\abs ~ (\neut~f) ~ a &&\dfun&& \neut~(f~\app~a)
\end{align*}

The neutral case is a congruence, and the function case is defined by
hereditary substitution of the argument into the function body.
Specifically, the $\sbe$ is called by extending the identity syntactic
environment $\idenv$ with the argument $a$.

\end{myproof}

\end{mylemma}

\begin{mylemma}{Primitive Recursion by Hereditary Substitution}{rbs}
{
\rbs : \rbsT
}
{
\refapp{nbs} & \reflem{abs} & $\abs$ & $\absT$ \\
}

Primitive Recursion by Hereditary Substitution recurses over a
syntactic natural number value ($\typv{\nat}$)
with two syntactic branch values ($\typv{C}$ and $\typv{C \arr C}$),
and returns a syntactic value ($\typv{C}$).

\begin{myproof}
{
By induction on the natural number value $\typv{\nat}$.
}
\begin{align*}
&\rbs ~ c_z ~ c_s ~ \zero &&\dfun&& c_z\\
&\rbs ~ c_z ~ c_s ~ (\suc~n) &&\dfun&& \abs~c_s~(\rbs~c_z~c_s~n)\\
&\rbs ~ c_z ~ c_s ~ (\neut~n) &&\dfun&& \neut~(\rec~c_z~c_s~n)
\end{align*}

The zero case is immediate and the neutral case is a congruence. The
successor case applies the successor branch to the inductive
hypothesis using $\abs$ (\reflem{abs}).

\end{myproof}

\end{mylemma}

\end{document}
